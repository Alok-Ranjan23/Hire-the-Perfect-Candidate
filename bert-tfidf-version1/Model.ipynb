{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b64bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learn engineering 13585abc knowledge innovation youll focus research building design selfrunning artificial intelligence ai system automate predictive model responsible design create ai algorithm capable learn make prediction define machine learn ml experience qualification  bachelor master degree mention course per requirement  02 year work experience provide analytics solution commercial set technical expertise must  machine learn cluster logistic regression classification  different library scikit learn numpy panda matplotlib seaborn  deep learning framework tensorflow kera pytorch application neural network model cnn rnn gans  familiar natural language processing associate library like nltk spacy beautiful soup  pyspark hadoop big data pipeline  data science methodology exploratory data analysis feature engineering model selection deployment model scale model evaluation  deploy nlp architecture computer vision model production consider plus  transformer advance technique nlp  familiar computer vision model object detection ocr opencv  analytical tool reduce medium data transfer  web framework like django database like mongodb nosql graphql  sql firebase aws azure google cloud platform job type full time\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from processing import train_data,test_data, job_req\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8535a7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learn engineering 13585abc knowledge innovation youll focus research building design selfrunning artificial intelligence ai system automate predictive model responsible design create ai algorithm capable learn make prediction define machine learn ml experience qualification  bachelor master degree mention course per requirement  02 year work experience provide analytics solution commercial set technical expertise must  machine learn cluster logistic regression classification  different library scikit learn numpy panda matplotlib seaborn  deep learning framework tensorflow kera pytorch application neural network model cnn rnn gans  familiar natural language processing associate library like nltk spacy beautiful soup  pyspark hadoop big data pipeline  data science methodology exploratory data analysis feature engineering model selection deployment model scale model evaluation  deploy nlp architecture computer vision model production consider plus  transformer advance technique nlp  familiar computer vision model object detection ocr opencv  analytical tool reduce medium data transfer  web framework like django database like mongodb nosql graphql  sql firebase aws azure google cloud platform job type full time\n"
     ]
    }
   ],
   "source": [
    "print(job_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "097564e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_cleaned_train = pd.DataFrame(train_data,columns=['documents'])\n",
    "doc_cleaned_test = pd.DataFrame(test_data,columns=['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be9b3ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  (90, 1)\n",
      "Size:  (60, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size: \", doc_cleaned_train.shape)\n",
    "print(\"Size: \", doc_cleaned_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08959ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_cleaned_trainX = doc_cleaned_train.append(pd.DataFrame([job_req],\n",
    "                                                          columns=['documents']),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dbaabe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cleaned_trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac56eda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>shawn buffet professional profile employment h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>work experience hsbc bank data analyst apr 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>stella thatcher executive profile work experie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>work experience hcl junior sdedata machine lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>machine learn engineering 13585abc knowledge i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            documents\n",
       "86  shawn buffet professional profile employment h...\n",
       "87  work experience hsbc bank data analyst apr 202...\n",
       "88  stella thatcher executive profile work experie...\n",
       "89  work experience hcl junior sdedata machine lea...\n",
       "90  machine learn engineering 13585abc knowledge i..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cleaned_trainX.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1063a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vec_train = sbert_model.encode(doc_cleaned_trainX['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "624a5cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vec_test = sbert_model.encode(doc_cleaned_test['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b69fa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (91, 768)\n"
     ]
    }
   ],
   "source": [
    "print(type(bert_vec_train),bert_vec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fa7ecf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (60, 768)\n"
     ]
    }
   ],
   "source": [
    "print(type(bert_vec_test),bert_vec_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6bfc55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.36280990e-01  6.02697611e-01  1.48722613e+00  5.63582122e-01\n",
      "  4.30839419e-01 -5.25903285e-01  2.36262396e-01 -4.47528899e-01\n",
      "  4.63868678e-01 -7.14169919e-01  1.55740470e-01  4.06883001e-01\n",
      "  3.35456103e-01  3.37730050e-02 -9.01125491e-01  3.99030626e-01\n",
      " -2.36999914e-01 -5.44585049e-01  9.14513230e-01 -2.98524380e-01\n",
      " -3.88934046e-01 -6.61903739e-01  6.63945973e-01  3.54603380e-01\n",
      "  5.44296622e-01  7.48070598e-01 -4.89221394e-01  3.87584716e-01\n",
      " -1.05052459e+00  4.70782518e-01 -1.23949718e+00  3.15410763e-01\n",
      " -8.79566073e-02 -6.50467992e-01 -3.15329522e-01  1.08649278e+00\n",
      "  5.25430262e-01  5.09093463e-01  5.93532860e-01 -7.97064826e-02\n",
      " -2.38123626e-01 -2.18719408e-01  5.07087037e-02 -3.78576845e-01\n",
      " -1.64505339e+00 -4.95772064e-01 -1.31360543e+00  1.21687325e-02\n",
      "  4.60826904e-01 -1.60238159e+00  4.95007075e-02  1.14434206e+00\n",
      "  4.59291995e-01 -4.95415807e-01 -4.16627586e-01  7.22935140e-01\n",
      "  5.45818567e-01 -1.28577077e+00 -3.43098551e-01 -4.63359207e-01\n",
      " -1.42241073e+00  6.66451752e-01  9.00672153e-02  1.66521192e-01\n",
      "  9.80386809e-02  2.98315823e-01  1.85027644e-02 -5.32556832e-01\n",
      " -1.28682733e+00 -4.99980062e-01 -2.93224126e-01 -8.14369977e-01\n",
      " -9.80243564e-01  8.80028978e-02 -7.30287373e-01 -5.43571591e-01\n",
      " -4.18979108e-01  7.69183517e-01  1.06996584e+00  1.11929619e+00\n",
      " -1.67031080e-01 -6.03378937e-02  4.15557921e-01 -6.85184479e-01\n",
      "  9.79007959e-01  5.38020849e-01  7.60898650e-01  3.65991563e-01\n",
      " -7.20201075e-01  1.02263130e-01  2.79380918e-01  2.23514125e-01\n",
      "  4.71316129e-01 -2.09302902e-01 -6.89480245e-01  1.45698324e-01\n",
      " -2.84963727e-01  3.64704490e-01 -4.72173572e-01  4.61068392e-01\n",
      " -3.74761373e-01 -6.44202232e-02 -4.40171719e-01  2.58929193e-01\n",
      " -2.14871958e-01  1.93267822e-01 -4.08827364e-01 -5.57454944e-01\n",
      " -1.01330209e+00  1.23745836e-01  9.97201324e-01 -1.78886950e-01\n",
      " -1.46064550e-01  1.04950272e-01 -1.15657255e-01 -6.17245972e-01\n",
      " -4.64373857e-01  1.01379263e+00  1.06917071e+00  2.47976556e-01\n",
      " -8.48013759e-02 -6.67828262e-01 -1.21932261e-01 -1.76205263e-01\n",
      "  3.08290869e-01  9.42730248e-01  2.61450976e-01  6.14781737e-01\n",
      "  1.78471729e-01 -8.20391551e-02  3.23170573e-01  6.19130194e-01\n",
      "  3.64130348e-01 -1.60833195e-01  2.92731494e-01  6.56028390e-01\n",
      " -2.62079954e-01 -3.78384739e-01  5.34068644e-01  1.87352151e-01\n",
      "  1.85613453e-01 -4.69130754e-01  9.56774414e-01 -8.35315585e-01\n",
      " -4.22743887e-01 -1.64521754e-01  9.68215242e-02 -6.81399524e-01\n",
      "  3.28150332e-01  2.11651713e-01  6.60234019e-02  5.62241673e-01\n",
      " -1.37061322e+00 -2.23509908e-01 -4.05920327e-01 -9.80831087e-02\n",
      " -9.12394404e-01 -6.14018798e-01  7.71772921e-01  3.94196421e-01\n",
      " -8.33772182e-01  8.85785103e-01 -6.02581441e-01  7.50331640e-01\n",
      "  2.19733432e-01 -1.02761173e+00  1.31163728e+00 -9.10064578e-01\n",
      "  1.20721869e-01 -7.01093003e-02 -9.71111596e-01  6.67283714e-01\n",
      "  1.84947407e+00  4.34649318e-01  1.15927351e+00  1.45616248e-01\n",
      "  6.35180831e-01 -7.07851410e-01 -5.57118058e-01 -6.16726875e-01\n",
      " -1.12086691e-01  3.45164627e-01 -9.88698125e-01  3.61066431e-01\n",
      "  4.36464101e-01 -9.24806967e-02  7.56273448e-01  3.15909423e-02\n",
      " -4.66280803e-02 -1.05316840e-01 -5.86083569e-02 -9.61913615e-02\n",
      "  1.70147583e-01 -4.88483101e-01 -3.15078974e-01  2.00816795e-01\n",
      " -9.04777229e-01  1.64993072e+00  4.38858539e-01  3.94652784e-01\n",
      " -3.41893822e-01 -2.48860866e-02 -1.51912272e-01 -6.28944874e-01\n",
      " -1.38608858e-01  3.29880387e-01  3.52509975e-01  1.95984095e-01\n",
      " -5.99699080e-01 -3.46966773e-01 -9.19065893e-01  5.34537248e-02\n",
      "  7.39732802e-01 -3.48431468e-01 -3.33369553e-01 -2.39965647e-01\n",
      "  3.01552564e-01 -6.61070868e-02  3.90843332e-01  4.74472582e-01\n",
      "  1.02132142e+00  3.84421438e-01 -4.49263841e-01  7.47729421e-01\n",
      " -5.27255058e-01  1.09520823e-01  7.35063493e-01 -6.05264187e-01\n",
      "  2.67307848e-01  4.39113110e-01  4.82024580e-01 -3.98146957e-01\n",
      " -9.11768228e-02  5.19852266e-02  2.18984678e-01  3.53983849e-01\n",
      " -1.05454099e+00  3.25544506e-01  5.59998214e-01  2.14187890e-01\n",
      " -1.27888611e-02  1.36368835e+00  1.22114144e-01  1.01385629e+00\n",
      " -4.98730928e-01 -4.17098939e-01  2.09778950e-01 -1.40101328e-01\n",
      " -7.98037648e-01 -8.36170763e-02 -1.05499256e+00  5.66531301e-01\n",
      " -1.41784048e-03 -5.66646159e-01 -5.77015877e-01  6.87669264e-03\n",
      " -6.00553639e-02  3.63587961e-02 -5.24909258e-01  7.82367051e-01\n",
      " -4.66368139e-01 -2.76332706e-01 -4.19786870e-02  4.80601281e-01\n",
      "  3.63224059e-01 -1.65398389e-01  2.62158141e-02  2.12630425e-02\n",
      " -2.21060902e-01  3.30446124e-01 -1.92955896e-01 -4.65129733e-01\n",
      " -7.97133520e-02  8.40736747e-01  3.12287182e-01 -5.68846345e-01\n",
      " -5.75968087e-01  8.52574036e-02  7.16910213e-02  3.62554610e-01\n",
      " -5.62652767e-01  4.59515661e-01 -5.16479671e-01 -7.20650852e-02\n",
      " -6.65346533e-02  7.64219686e-02  2.69259602e-01  1.75710261e-01\n",
      " -3.65612060e-01 -7.93605447e-02 -3.88315201e-01 -6.90072253e-02\n",
      " -4.45554376e-01  2.62654901e-01  3.77282858e-01 -3.57382894e-01\n",
      "  1.19077373e+00 -5.68233311e-01  9.87645268e-01 -4.04606909e-01\n",
      " -3.52089673e-01  7.53446519e-02 -9.46955323e-01  2.90984124e-01\n",
      "  3.23863924e-01 -3.43693942e-01  4.40473348e-01 -1.33559912e-01\n",
      " -1.22645772e+00 -8.42508435e-01 -3.25537473e-01 -6.14488780e-01\n",
      "  7.34432220e-01  5.72420180e-01  3.96932483e-01  2.19521210e-01\n",
      " -4.05336380e-01  7.18479306e-02  2.56913722e-01 -3.75719428e-01\n",
      " -2.79639870e-01  3.39531824e-02 -9.03953090e-02 -5.39968200e-02\n",
      "  8.76915812e-01 -5.78037612e-02  2.51554072e-01  5.03946058e-02\n",
      " -3.77656102e-01 -6.34067729e-02  8.38889062e-01  2.18243629e-01\n",
      "  7.16352761e-01  4.15942311e-01 -4.10209328e-01  5.15026033e-01\n",
      " -6.81295455e-01 -6.57018870e-02  3.31223458e-01 -7.96993136e-01\n",
      "  1.04899085e+00  3.43018502e-01 -1.07479431e-02  5.82634389e-01\n",
      "  6.38847575e-02 -9.84358191e-02  1.10652256e+00  7.75454342e-01\n",
      " -9.03685927e-01  3.14188480e-01  4.96822774e-01  6.74381480e-02\n",
      "  7.23885179e-01 -1.21434316e-01 -1.64928928e-01  3.87583613e-01\n",
      "  2.97364861e-01  2.52517700e-01 -8.87523234e-01  2.83477396e-01\n",
      " -1.28482714e-01  2.21536875e-01 -6.79969639e-02 -2.78056771e-01\n",
      " -4.47029173e-02  4.19309855e-01 -4.04033601e-01  4.30027656e-02\n",
      "  7.73764193e-01 -4.52187777e-01 -7.01290369e-02  1.69410512e-01\n",
      " -6.62427962e-01 -1.63851753e-01 -3.20909888e-01 -3.22987109e-01\n",
      " -5.92285037e-01 -3.78024042e-01 -3.75618041e-01 -4.51437712e-01\n",
      "  1.26276329e-01 -9.54412162e-01  6.47658706e-01 -3.65798138e-02\n",
      " -1.50102526e-01  1.14402071e-01  1.44178301e-01  3.13952655e-01\n",
      " -2.29462273e-02  1.98659018e-01  5.54216325e-01  5.13847768e-01\n",
      "  1.54462829e-01  1.64640173e-01  2.46660337e-01 -3.08178842e-01\n",
      " -4.90573943e-01 -2.40366235e-01 -1.90364569e-01 -4.32034910e-01\n",
      "  7.59498449e-03 -3.94465387e-01  1.14190805e+00 -5.93637884e-01\n",
      "  3.07808399e-01  2.05554202e-01  1.71086118e-01 -1.23503757e+00\n",
      "  6.02525398e-02 -9.35978949e-01 -1.93984970e-01 -6.66731358e-01\n",
      "  4.20471251e-01  2.51181930e-01 -3.37592214e-01  2.23877504e-01\n",
      "  1.80149719e-01 -9.04112607e-02 -1.06025887e+00  8.30914319e-01\n",
      " -4.22980964e-01 -1.01460144e-02  1.52745008e-01  1.32328629e-01\n",
      " -3.51510257e-01  2.24890351e-01 -3.68043572e-01 -9.45270211e-02\n",
      " -1.03785992e+00 -1.03949895e-02 -1.65556490e-01 -2.33098082e-02\n",
      " -7.06328332e-01  3.71401250e-01  7.64214516e-01  4.00694720e-02\n",
      "  4.90593970e-01 -5.73113918e-01  6.13320351e-01 -5.19244492e-01\n",
      " -2.44201913e-01 -1.22778308e+00  8.49715114e-01 -4.09734577e-01\n",
      " -1.68590873e-01  1.10027373e+00  1.97504237e-01  4.90840912e-01\n",
      "  6.72289312e-01  2.22235799e-01  9.63870525e-01 -1.01673210e+00\n",
      "  2.76266962e-01  2.19614968e-01  3.45190793e-01  1.38389826e-01\n",
      " -5.96999466e-01 -1.32088149e+00 -9.68621612e-01 -3.70220184e-01\n",
      "  7.26738945e-02 -3.93705219e-01  2.44401067e-01 -2.27526054e-01\n",
      "  3.85615051e-01  1.07753918e-01 -5.21936864e-02 -2.09940746e-01\n",
      " -2.07350031e-01 -9.87478733e-01  2.46763408e-01 -3.85908067e-01\n",
      "  4.63778913e-01  1.23547196e+00  1.53278366e-01 -1.49004555e+00\n",
      " -7.41465747e-01  4.10856426e-01  3.20747755e-02  9.37710330e-02\n",
      " -3.96497488e-01 -3.31335247e-01  4.09454219e-02  5.55651188e-01\n",
      "  5.34760952e-01 -7.18401253e-01 -1.68584026e-02  8.20614934e-01\n",
      " -3.51239473e-01 -1.81591108e-01  3.80044460e-01  1.80596292e-01\n",
      " -4.27791536e-01 -5.88268101e-01  4.77185875e-01 -2.70286143e-01\n",
      " -1.91180035e-01  3.23520720e-01  9.90616232e-02 -2.54272610e-01\n",
      "  1.15422618e+00  3.94899622e-02  4.56185266e-02  2.94647723e-01\n",
      "  1.36476696e+00  1.14407504e+00 -4.77181107e-01 -3.12021106e-01\n",
      "  4.61776778e-02  5.58827780e-02 -2.58624464e-01  3.64478886e-01\n",
      "  6.93599820e-01 -3.32578272e-01 -8.14452171e-01  5.39816558e-01\n",
      " -4.65321839e-02 -2.92048872e-01 -1.92504808e-01  1.07488409e-01\n",
      " -2.74129212e-01  7.18356147e-02  9.86685395e-01 -8.85514021e-01\n",
      " -1.14821471e-01  4.17713732e-01  1.41237170e-01  3.63440484e-01\n",
      "  4.26279716e-02  4.08051819e-01 -6.36175632e-01  1.45772770e-01\n",
      "  4.33377594e-01  4.22178209e-01 -1.69908404e-01 -5.54452598e-01\n",
      " -1.53845936e-01 -1.07136585e-01  3.65351021e-01 -7.33778298e-01\n",
      "  9.41962451e-02  2.08177984e-01  3.37818444e-01 -9.45262551e-01\n",
      " -4.97622758e-01  1.95614532e-01  1.62885696e-01 -3.83085877e-01\n",
      " -1.14368343e+00 -6.94707632e-01 -7.00142682e-01 -4.89332348e-01\n",
      "  3.40449989e-01  6.66710198e-01 -2.09456369e-01  2.71732092e-01\n",
      " -7.47455597e-01  4.46232080e-01  5.48621751e-02  4.03425902e-01\n",
      "  2.17573177e-02  8.85139525e-01 -4.54215169e-01  2.11394932e-02\n",
      " -3.29188794e-01 -6.22766435e-01 -2.22269937e-01 -6.28217280e-01\n",
      " -9.44372416e-01 -3.38049829e-01  2.23991081e-01  1.01861447e-01\n",
      "  2.02907294e-01  9.15173948e-01 -9.60035086e-01 -1.09526503e+00\n",
      "  6.61324561e-01 -9.48301017e-01  2.58108824e-01  4.08188522e-01\n",
      " -3.24091941e-01  7.51892745e-01 -1.81095973e-01  1.71647325e-01\n",
      "  1.35565093e-02  6.09602742e-02  6.45253062e-01  3.27894390e-01\n",
      " -2.98024505e-01  2.56695777e-01 -7.24766254e-01  1.86130237e-02\n",
      "  3.24111968e-01  5.37188232e-01  3.02479714e-01 -3.00884217e-01\n",
      "  2.09245935e-01  6.42572820e-01  3.75597209e-01 -6.35615647e-01\n",
      "  2.06455916e-01 -8.38804007e-01 -1.23938203e+00  6.76762342e-01\n",
      " -6.48379266e-01 -2.32611105e-01 -4.02892530e-01  2.10819334e-01\n",
      " -4.18296605e-01  7.27150798e-01  3.10000360e-01 -2.77221382e-01\n",
      " -1.98982358e-01  1.79622322e-01 -4.18012142e-01 -1.83954522e-01\n",
      " -4.54789996e-01 -6.08410001e-01 -2.71030635e-01  1.52371675e-01\n",
      "  4.23712105e-01  7.93996990e-01 -6.08318925e-01 -6.26323104e-01\n",
      "  1.52382135e-01 -7.56180227e-01 -1.32507741e-01  2.53269613e-01\n",
      " -1.23767734e+00  9.05638933e-02  1.99312970e-01 -1.70060426e-01\n",
      "  4.23920691e-01  4.34144437e-01 -1.36542737e-01  6.90444171e-01\n",
      " -7.38316715e-01  6.83116689e-02  7.97127746e-03  4.99130815e-01\n",
      " -8.65796447e-01  1.49738395e+00 -2.75559217e-01 -1.92950785e-01\n",
      "  6.11063659e-01 -6.79873765e-01  3.95575225e-01  3.00287694e-01\n",
      "  6.29093587e-01  7.39307404e-01  8.09761167e-01  1.00048506e+00\n",
      " -3.83693010e-01 -1.07134484e-01  4.77611780e-01  2.25869775e-01\n",
      " -3.49275082e-01  1.03474498e-01 -2.80470014e-01  7.72663116e-01\n",
      "  3.74817923e-02 -2.59354532e-01  3.53341907e-01 -5.23404002e-01\n",
      "  8.79142344e-01  3.25453550e-01  2.25661367e-01  2.50611752e-01\n",
      "  5.43027930e-02 -3.17164540e-01  5.79044938e-01 -4.12440717e-01\n",
      " -4.88138884e-01 -8.10585320e-01  1.00496089e+00 -5.66999018e-02\n",
      "  2.42325038e-01  3.92080694e-01  1.79152593e-01 -8.52786779e-01\n",
      " -3.31076562e-01 -4.21217084e-01 -6.76598167e-04 -8.97360742e-01\n",
      "  6.87775075e-01  1.17890522e-01 -6.78824425e-01  1.26959309e-01\n",
      " -1.76862441e-02  1.03859830e+00  3.24439287e-01 -5.94484806e-02\n",
      " -3.39217484e-01 -6.38445497e-01 -2.78358787e-01 -4.32253718e-01\n",
      " -2.96087027e-01  1.19007029e-01  3.83862555e-01  1.67671055e-01\n",
      " -7.23088622e-01  8.39327097e-01 -6.14902973e-01 -3.02129060e-01\n",
      " -2.19477847e-01 -5.79040051e-01 -6.25955760e-02 -8.43321905e-02\n",
      " -1.17456086e-01 -4.17025596e-01  3.01305987e-02  8.25476348e-01\n",
      " -1.49307668e-01 -1.98727340e-01 -5.74363828e-01  1.00279009e+00\n",
      "  3.42301250e-01 -3.54062796e-01  1.28193423e-01  4.02434975e-01\n",
      "  1.43907294e-01 -1.91149190e-01  4.71573994e-02 -9.11640882e-01\n",
      " -1.05879225e-01 -1.31337613e-01  4.05206829e-01  4.82815981e-01\n",
      " -5.48335731e-01 -7.33755231e-02  1.47486305e+00 -8.86626780e-01\n",
      " -3.41120273e-01  1.99972391e-01 -2.43219540e-01  1.06818773e-01\n",
      "  9.08540711e-02 -8.25740218e-01 -6.38156950e-01 -1.49752831e+00\n",
      " -6.35467589e-01  4.50879127e-01 -5.53431869e-01 -6.84664235e-04\n",
      "  5.65175116e-02  3.29450220e-01  9.89170372e-02  1.77597582e-01\n",
      " -1.98770598e-01  6.49207115e-01  6.04685903e-01 -6.48775518e-01\n",
      "  8.77274573e-02  1.42299330e+00 -3.58967543e-01  2.66213089e-01\n",
      " -2.47746184e-01 -2.94958383e-01 -3.04397762e-01 -2.92131543e-01\n",
      " -1.02685118e+00 -1.31354368e+00 -2.81848073e-01 -5.12925088e-01\n",
      " -5.75421751e-01 -6.46397412e-01 -5.37252545e-01  3.58076215e-01]\n"
     ]
    }
   ],
   "source": [
    "print(bert_vec_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "444f218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Append TFidf vectorizer\n",
    "tfidfvectorizer = TfidfVectorizer()\n",
    "tfidf_train_vect = tfidfvectorizer.fit_transform(doc_cleaned_trainX['documents'])\n",
    "tfidf_test_vec=tfidfvectorizer.transform(doc_cleaned_test['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33d3647c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfidf_train_vect[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8d4e28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1931)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_train_vect[0].toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "849ddd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize bert vector\n",
    "bert_vec_train_normalize = []\n",
    "for bert_feature in bert_vec_train:\n",
    "    bert_vec_train_normalize.append(bert_feature/np.sqrt(np.dot(bert_feature,bert_feature.T)))\n",
    "    \n",
    "bert_vec_test_normalize = []\n",
    "for bert_feature in bert_vec_test:\n",
    "    bert_vec_test_normalize.append(bert_feature/np.sqrt(np.dot(bert_feature,bert_feature.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba939b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "feature_vec_train = []\n",
    "feature_vec_test = []\n",
    "for bert_feature, tfidf_feature in zip(bert_vec_train_normalize,tfidf_train_vect):\n",
    "    feature_vec_train.append(np.append(bert_feature,np.squeeze(tfidf_feature.toarray().T)))\n",
    "    \n",
    "for bert_feature, tfidf_feature in zip(bert_vec_test_normalize,tfidf_test_vec):\n",
    "    feature_vec_test.append(np.append(bert_feature,np.squeeze(tfidf_feature.toarray().T)))    \n",
    "\n",
    "print(len(feature_vec_train))\n",
    "print(len(feature_vec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "734234db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_vec = feature_vec_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f39ea78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f8b604",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d05f823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'app.py',\n",
       " 'bertFeature.pkl',\n",
       " 'feature.ipynb',\n",
       " 'Model.ipynb',\n",
       " 'processing.py',\n",
       " 'read_pdf.py',\n",
       " 'Siamese Network.ipynb',\n",
       " 'static',\n",
       " 'submission.csv',\n",
       " 'templates',\n",
       " 'tfidf.pkl',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efbeaa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CandidateID</th>\n",
       "      <th>Match Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>candidate_011</td>\n",
       "      <td>13.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>candidate_113</td>\n",
       "      <td>36.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate_123</td>\n",
       "      <td>54.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>candidate_012</td>\n",
       "      <td>41.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candidate_002</td>\n",
       "      <td>48.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CandidateID  Match Percentage\n",
       "0  candidate_011             13.60\n",
       "1  candidate_113             36.63\n",
       "2  candidate_123             54.93\n",
       "3  candidate_012             41.46\n",
       "4  candidate_002             48.91"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../dataset/train.csv')\n",
    "test = pd.read_csv('../dataset/test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1016798f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CandidateID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>candidate_014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>candidate_098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate_075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>candidate_016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candidate_131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CandidateID\n",
       "0  candidate_014\n",
       "1  candidate_098\n",
       "2  candidate_075\n",
       "3  candidate_016\n",
       "4  candidate_131"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b3e7d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28ab4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vec_train = feature_vec_train[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93876760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_vec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1d24e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_vec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11d1a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bert-tfidf'] = feature_vec_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2be8d10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CandidateID</th>\n",
       "      <th>Match Percentage</th>\n",
       "      <th>bert-tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>candidate_011</td>\n",
       "      <td>13.60</td>\n",
       "      <td>[-0.035068921744823456, 0.03941209241747856, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>candidate_113</td>\n",
       "      <td>36.63</td>\n",
       "      <td>[-0.005496754311025143, 0.05249103158712387, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate_123</td>\n",
       "      <td>54.93</td>\n",
       "      <td>[0.006635388825088739, 0.03635752946138382, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>candidate_012</td>\n",
       "      <td>41.46</td>\n",
       "      <td>[-0.03602419048547745, 0.06374359875917435, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candidate_002</td>\n",
       "      <td>48.91</td>\n",
       "      <td>[-0.04800780862569809, 0.051136553287506104, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CandidateID  Match Percentage  \\\n",
       "0  candidate_011             13.60   \n",
       "1  candidate_113             36.63   \n",
       "2  candidate_123             54.93   \n",
       "3  candidate_012             41.46   \n",
       "4  candidate_002             48.91   \n",
       "\n",
       "                                          bert-tfidf  \n",
       "0  [-0.035068921744823456, 0.03941209241747856, 0...  \n",
       "1  [-0.005496754311025143, 0.05249103158712387, 0...  \n",
       "2  [0.006635388825088739, 0.03635752946138382, 0....  \n",
       "3  [-0.03602419048547745, 0.06374359875917435, 0....  \n",
       "4  [-0.04800780862569809, 0.051136553287506104, 0...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d35a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['bert-tfidf'] = feature_vec_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6faa1d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CandidateID</th>\n",
       "      <th>bert-tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>candidate_014</td>\n",
       "      <td>[-0.019855467602610588, 0.05377298220992088, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>candidate_098</td>\n",
       "      <td>[-0.0040850285440683365, 0.06921227276325226, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate_075</td>\n",
       "      <td>[-0.051488179713487625, 0.04464828595519066, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>candidate_016</td>\n",
       "      <td>[-0.03214683011174202, 0.03543371334671974, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candidate_131</td>\n",
       "      <td>[-0.017553701996803284, 0.05723244696855545, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CandidateID                                         bert-tfidf\n",
       "0  candidate_014  [-0.019855467602610588, 0.05377298220992088, 0...\n",
       "1  candidate_098  [-0.0040850285440683365, 0.06921227276325226, ...\n",
       "2  candidate_075  [-0.051488179713487625, 0.04464828595519066, 0...\n",
       "3  candidate_016  [-0.03214683011174202, 0.03543371334671974, 0....\n",
       "4  candidate_131  [-0.017553701996803284, 0.05723244696855545, 0..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3a370d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train['bert-tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45e4529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out = train['Match Percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a207ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_ref = np.array([np.array(ref_vec)]*train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e247df1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 2699)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7cb75c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02544418,  0.06062744,  0.05386385, ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ref[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d1c725a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02544418,  0.06062744,  0.05386385, ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ref[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea6a1d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b63a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = np.array(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebb9c0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02544418,  0.06062744,  0.05386385, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.02544418,  0.06062744,  0.05386385, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.02544418,  0.06062744,  0.05386385, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.02544418,  0.06062744,  0.05386385, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.02544418,  0.06062744,  0.05386385, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.02544418,  0.06062744,  0.05386385, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5584d8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([-0.03506892,  0.03941209,  0.0972539 , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.00549675,  0.05249103,  0.10540436, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([0.00663539, 0.03635753, 0.11206844, ..., 0.        , 0.        ,\n",
       "       0.        ]),\n",
       "       array([-0.03602419,  0.0637436 ,  0.07993563, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04800781,  0.05113655,  0.08350185, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03954075,  0.033113  ,  0.11144097, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02977174,  0.05882068,  0.08391549, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.01046504,  0.06473319,  0.08585075, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.05801979,  0.06134104,  0.12003814, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0245129 ,  0.05920603,  0.07965789, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02696748,  0.04930975,  0.11210301, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0278991 ,  0.05666241,  0.10923066, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02967755,  0.02792333,  0.10492571, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02574873,  0.04033441,  0.08613167, ...,  0.        ,\n",
       "        0.        ,  0.1370702 ]),\n",
       "       array([-0.02221902,  0.04419983,  0.0863772 , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03663709,  0.05024071,  0.10059232, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04600909,  0.04738539,  0.097515  , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0221873 ,  0.0490326 ,  0.08469099, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.01806444,  0.06825376,  0.09123397, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04842588,  0.05324432,  0.09534659, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03396363,  0.03642053,  0.12540986, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.01793087,  0.04757039,  0.09264449, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03480851,  0.03501147,  0.06159562, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04281674,  0.045093  ,  0.07957116, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04777335,  0.05200522,  0.09464517, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.05118988,  0.03638849,  0.10349054, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04529372,  0.03701129,  0.11101111, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0258727 ,  0.02296119,  0.09101973, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03465793,  0.04503412,  0.09713047, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.01984432,  0.04336196,  0.09785452, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0386589 ,  0.05534377,  0.07603604, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0202014 ,  0.04677384,  0.10797663, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02305587,  0.03490947,  0.10007174, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04980198,  0.03812968,  0.10519821, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03436195,  0.05456175,  0.08508614, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04176027,  0.05491177,  0.09739007, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03535032,  0.04311647,  0.09684633, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04486177,  0.04005459,  0.06610878, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02393508,  0.06341978,  0.07533564, ...,  0.        ,\n",
       "        0.17779068,  0.        ]),\n",
       "       array([-0.04618952,  0.03682629,  0.09140056, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04541603,  0.0518854 ,  0.1197806 , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.05175994,  0.04854551,  0.08130327, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02262257,  0.0507374 ,  0.09332427, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0211736 ,  0.04347858,  0.09291975, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0392882 ,  0.05824057,  0.09912079, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-6.77056232e-05,  4.80234139e-02,  1.23275302e-01, ...,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00]),\n",
       "       array([-0.02838291,  0.00590238,  0.12535505, ...,  0.1587994 ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04926392,  0.02849773,  0.07807832, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0530745 ,  0.05309968,  0.05074241, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02952067,  0.05588126,  0.05949331, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02913095,  0.06170619,  0.06907174, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.027273  ,  0.05410664,  0.09463757, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04375102,  0.04336125,  0.09115811, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02476109,  0.03412418,  0.12225243, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04052863,  0.04216396,  0.07672723, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02606647,  0.04374701,  0.12406275, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0356055 ,  0.0491006 ,  0.09983907, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0158638 ,  0.04291073,  0.10393162, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03916518,  0.03783995,  0.08827338, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03666386,  0.03920842,  0.11625986, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0303917 ,  0.0368039 ,  0.10063425, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04235798,  0.03245078,  0.11372443, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03549132,  0.04361402,  0.09695739, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03360648,  0.06046509,  0.11455557, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0253822 ,  0.04711699,  0.08639684, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03351801,  0.06643338,  0.0681053 , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0355155 ,  0.06612367,  0.0857618 , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04064998,  0.04128427,  0.1070505 , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0314254 ,  0.0462313 ,  0.09940581, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02628941,  0.02464807,  0.08103883, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02834234,  0.03425329,  0.10322239, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04079945,  0.0572875 ,  0.11796635, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02783829,  0.04732914,  0.10381124, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.05161508,  0.04310218,  0.08458728, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.054052  ,  0.03534394,  0.097061  , ...,  0.12820916,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02207506,  0.06033181,  0.07777642, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04031119,  0.03664425,  0.11283877, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03624265,  0.01990811,  0.06453243, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02640952,  0.06151931,  0.08087938, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02974494,  0.05546594,  0.11617713, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03791315,  0.05057952,  0.06324989, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02815875,  0.04024189,  0.08532034, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04936205,  0.03605616,  0.08797168, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02871966,  0.05074386,  0.09160688, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0335101 ,  0.04265147,  0.09526831, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03275182,  0.05183841,  0.09606834, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03356318,  0.04098739,  0.06688333, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.05225945,  0.02827501,  0.05655041, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03730652,  0.04339013,  0.08583303, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03939362,  0.04720744,  0.08371635, ...,  0.        ,\n",
       "        0.        ,  0.        ])], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a7c9d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset:: train_df, train_out, train_df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4f559ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ab4a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26fa8a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_df_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9b9bd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2699"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf3b69b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2699"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ref.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c6c5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.DataFrame(np.arange(2699).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e35bfa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2689</th>\n",
       "      <th>2690</th>\n",
       "      <th>2691</th>\n",
       "      <th>2692</th>\n",
       "      <th>2693</th>\n",
       "      <th>2694</th>\n",
       "      <th>2695</th>\n",
       "      <th>2696</th>\n",
       "      <th>2697</th>\n",
       "      <th>2698</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2689</td>\n",
       "      <td>2690</td>\n",
       "      <td>2691</td>\n",
       "      <td>2692</td>\n",
       "      <td>2693</td>\n",
       "      <td>2694</td>\n",
       "      <td>2695</td>\n",
       "      <td>2696</td>\n",
       "      <td>2697</td>\n",
       "      <td>2698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2699 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  2689  \\\n",
       "0     0     1     2     3     4     5     6     7     8     9  ...  2689   \n",
       "\n",
       "   2690  2691  2692  2693  2694  2695  2696  2697  2698  \n",
       "0  2690  2691  2692  2693  2694  2695  2696  2697  2698  \n",
       "\n",
       "[1 rows x 2699 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "10def6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 2699)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in train_df.tolist():\n",
    "    df_train = df_train.append(pd.DataFrame(i.reshape(1,-1)),ignore_index=True)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "31d8c465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2689</th>\n",
       "      <th>2690</th>\n",
       "      <th>2691</th>\n",
       "      <th>2692</th>\n",
       "      <th>2693</th>\n",
       "      <th>2694</th>\n",
       "      <th>2695</th>\n",
       "      <th>2696</th>\n",
       "      <th>2697</th>\n",
       "      <th>2698</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2689.0</td>\n",
       "      <td>2690.0</td>\n",
       "      <td>2691.0</td>\n",
       "      <td>2692.0</td>\n",
       "      <td>2693.0</td>\n",
       "      <td>2694.0</td>\n",
       "      <td>2695.0</td>\n",
       "      <td>2696.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>2698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.035069</td>\n",
       "      <td>0.039412</td>\n",
       "      <td>0.097254</td>\n",
       "      <td>0.036854</td>\n",
       "      <td>0.028174</td>\n",
       "      <td>-0.034390</td>\n",
       "      <td>0.015450</td>\n",
       "      <td>-0.029265</td>\n",
       "      <td>0.030334</td>\n",
       "      <td>-0.046702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005497</td>\n",
       "      <td>0.052491</td>\n",
       "      <td>0.105404</td>\n",
       "      <td>0.015922</td>\n",
       "      <td>0.045108</td>\n",
       "      <td>-0.026445</td>\n",
       "      <td>0.020454</td>\n",
       "      <td>-0.021225</td>\n",
       "      <td>0.029388</td>\n",
       "      <td>-0.036155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.036358</td>\n",
       "      <td>0.112068</td>\n",
       "      <td>0.038493</td>\n",
       "      <td>0.052563</td>\n",
       "      <td>-0.034066</td>\n",
       "      <td>0.033940</td>\n",
       "      <td>-0.015944</td>\n",
       "      <td>0.030683</td>\n",
       "      <td>-0.045047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.036024</td>\n",
       "      <td>0.063744</td>\n",
       "      <td>0.079936</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>0.052921</td>\n",
       "      <td>-0.034398</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>-0.010511</td>\n",
       "      <td>0.024116</td>\n",
       "      <td>-0.036431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-0.032752</td>\n",
       "      <td>0.051838</td>\n",
       "      <td>0.096068</td>\n",
       "      <td>0.025798</td>\n",
       "      <td>0.039043</td>\n",
       "      <td>-0.034132</td>\n",
       "      <td>0.023987</td>\n",
       "      <td>-0.008339</td>\n",
       "      <td>0.029089</td>\n",
       "      <td>-0.040122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.033563</td>\n",
       "      <td>0.040987</td>\n",
       "      <td>0.066883</td>\n",
       "      <td>0.027389</td>\n",
       "      <td>0.060639</td>\n",
       "      <td>-0.010191</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>-0.019023</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>-0.015269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>-0.052259</td>\n",
       "      <td>0.028275</td>\n",
       "      <td>0.056550</td>\n",
       "      <td>0.016858</td>\n",
       "      <td>0.084523</td>\n",
       "      <td>-0.024778</td>\n",
       "      <td>-0.024169</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.013114</td>\n",
       "      <td>-0.045715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.037307</td>\n",
       "      <td>0.043390</td>\n",
       "      <td>0.085833</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>0.057149</td>\n",
       "      <td>-0.014987</td>\n",
       "      <td>-0.007999</td>\n",
       "      <td>-0.021718</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>-0.039752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-0.039394</td>\n",
       "      <td>0.047207</td>\n",
       "      <td>0.083716</td>\n",
       "      <td>0.021852</td>\n",
       "      <td>0.033309</td>\n",
       "      <td>-0.035354</td>\n",
       "      <td>0.027014</td>\n",
       "      <td>-0.020229</td>\n",
       "      <td>0.020467</td>\n",
       "      <td>-0.033394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 2699 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "0   0.000000  1.000000  2.000000  3.000000  4.000000  5.000000  6.000000   \n",
       "1  -0.035069  0.039412  0.097254  0.036854  0.028174 -0.034390  0.015450   \n",
       "2  -0.005497  0.052491  0.105404  0.015922  0.045108 -0.026445  0.020454   \n",
       "3   0.006635  0.036358  0.112068  0.038493  0.052563 -0.034066  0.033940   \n",
       "4  -0.036024  0.063744  0.079936  0.014825  0.052921 -0.034398  0.010311   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "86 -0.032752  0.051838  0.096068  0.025798  0.039043 -0.034132  0.023987   \n",
       "87 -0.033563  0.040987  0.066883  0.027389  0.060639 -0.010191  0.000841   \n",
       "88 -0.052259  0.028275  0.056550  0.016858  0.084523 -0.024778 -0.024169   \n",
       "89 -0.037307  0.043390  0.085833  0.008274  0.057149 -0.014987 -0.007999   \n",
       "90 -0.039394  0.047207  0.083716  0.021852  0.033309 -0.035354  0.027014   \n",
       "\n",
       "        7         8         9     ...    2689    2690    2691    2692    2693  \\\n",
       "0   7.000000  8.000000  9.000000  ...  2689.0  2690.0  2691.0  2692.0  2693.0   \n",
       "1  -0.029265  0.030334 -0.046702  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "2  -0.021225  0.029388 -0.036155  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "3  -0.015944  0.030683 -0.045047  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "4  -0.010511  0.024116 -0.036431  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "..       ...       ...       ...  ...     ...     ...     ...     ...     ...   \n",
       "86 -0.008339  0.029089 -0.040122  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "87 -0.019023  0.000316 -0.015269  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "88  0.007519  0.013114 -0.045715  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "89 -0.021718  0.020348 -0.039752  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "90 -0.020229  0.020467 -0.033394  ...     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      2694    2695    2696    2697    2698  \n",
       "0   2694.0  2695.0  2696.0  2697.0  2698.0  \n",
       "1      0.0     0.0     0.0     0.0     0.0  \n",
       "2      0.0     0.0     0.0     0.0     0.0  \n",
       "3      0.0     0.0     0.0     0.0     0.0  \n",
       "4      0.0     0.0     0.0     0.0     0.0  \n",
       "..     ...     ...     ...     ...     ...  \n",
       "86     0.0     0.0     0.0     0.0     0.0  \n",
       "87     0.0     0.0     0.0     0.0     0.0  \n",
       "88     0.0     0.0     0.0     0.0     0.0  \n",
       "89     0.0     0.0     0.0     0.0     0.0  \n",
       "90     0.0     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[91 rows x 2699 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2dd79ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6     \\\n",
      "1  -0.035069  0.039412  0.097254  0.036854  0.028174 -0.034390  0.015450   \n",
      "2  -0.005497  0.052491  0.105404  0.015922  0.045108 -0.026445  0.020454   \n",
      "3   0.006635  0.036358  0.112068  0.038493  0.052563 -0.034066  0.033940   \n",
      "4  -0.036024  0.063744  0.079936  0.014825  0.052921 -0.034398  0.010311   \n",
      "5  -0.048008  0.051137  0.083502  0.033642  0.055629 -0.034949  0.008873   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "86 -0.032752  0.051838  0.096068  0.025798  0.039043 -0.034132  0.023987   \n",
      "87 -0.033563  0.040987  0.066883  0.027389  0.060639 -0.010191  0.000841   \n",
      "88 -0.052259  0.028275  0.056550  0.016858  0.084523 -0.024778 -0.024169   \n",
      "89 -0.037307  0.043390  0.085833  0.008274  0.057149 -0.014987 -0.007999   \n",
      "90 -0.039394  0.047207  0.083716  0.021852  0.033309 -0.035354  0.027014   \n",
      "\n",
      "        7         8         9     ...  2689  2690  2691  2692  2693  2694  \\\n",
      "1  -0.029265  0.030334 -0.046702  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2  -0.021225  0.029388 -0.036155  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "3  -0.015944  0.030683 -0.045047  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "4  -0.010511  0.024116 -0.036431  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "5  -0.019531  0.024946 -0.039330  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "..       ...       ...       ...  ...   ...   ...   ...   ...   ...   ...   \n",
      "86 -0.008339  0.029089 -0.040122  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "87 -0.019023  0.000316 -0.015269  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "88  0.007519  0.013114 -0.045715  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "89 -0.021718  0.020348 -0.039752  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "90 -0.020229  0.020467 -0.033394  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "    2695  2696  2697  2698  \n",
      "1    0.0   0.0   0.0   0.0  \n",
      "2    0.0   0.0   0.0   0.0  \n",
      "3    0.0   0.0   0.0   0.0  \n",
      "4    0.0   0.0   0.0   0.0  \n",
      "5    0.0   0.0   0.0   0.0  \n",
      "..   ...   ...   ...   ...  \n",
      "86   0.0   0.0   0.0   0.0  \n",
      "87   0.0   0.0   0.0   0.0  \n",
      "88   0.0   0.0   0.0   0.0  \n",
      "89   0.0   0.0   0.0   0.0  \n",
      "90   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[90 rows x 2699 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train=df_train.iloc[1:,:]\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c88c0715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 2699)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ref=pd.DataFrame(np.arange(2699).reshape(1,-1))\n",
    "for i in train_df_ref.tolist():\n",
    "    df_train_ref = df_train_ref.append(pd.DataFrame(np.array(i).reshape(1,-1)),ignore_index=True)\n",
    "df_train_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0818cd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2689</th>\n",
       "      <th>2690</th>\n",
       "      <th>2691</th>\n",
       "      <th>2692</th>\n",
       "      <th>2693</th>\n",
       "      <th>2694</th>\n",
       "      <th>2695</th>\n",
       "      <th>2696</th>\n",
       "      <th>2697</th>\n",
       "      <th>2698</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.025444</td>\n",
       "      <td>0.060627</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.033361</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>-0.024353</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>-0.032432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.025444</td>\n",
       "      <td>0.060627</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.033361</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>-0.024353</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>-0.032432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.025444</td>\n",
       "      <td>0.060627</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.033361</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>-0.024353</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>-0.032432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.025444</td>\n",
       "      <td>0.060627</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.033361</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>-0.024353</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>-0.032432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.025444</td>\n",
       "      <td>0.060627</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.033361</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>-0.024353</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>-0.032432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-0.025444</td>\n",
       "      <td>0.060627</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.033361</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>-0.024353</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>-0.032432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.025444</td>\n",
       "      <td>0.060627</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.033361</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>-0.024353</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>-0.032432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>-0.025444</td>\n",
       "      <td>0.060627</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.033361</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>-0.024353</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>-0.032432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.025444</td>\n",
       "      <td>0.060627</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.033361</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>-0.024353</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>-0.032432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-0.025444</td>\n",
       "      <td>0.060627</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.033361</td>\n",
       "      <td>0.049359</td>\n",
       "      <td>-0.024353</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>-0.014916</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>-0.032432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 2699 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "1  -0.025444  0.060627  0.053864  0.033361  0.049359 -0.024353  0.020693   \n",
       "2  -0.025444  0.060627  0.053864  0.033361  0.049359 -0.024353  0.020693   \n",
       "3  -0.025444  0.060627  0.053864  0.033361  0.049359 -0.024353  0.020693   \n",
       "4  -0.025444  0.060627  0.053864  0.033361  0.049359 -0.024353  0.020693   \n",
       "5  -0.025444  0.060627  0.053864  0.033361  0.049359 -0.024353  0.020693   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "86 -0.025444  0.060627  0.053864  0.033361  0.049359 -0.024353  0.020693   \n",
       "87 -0.025444  0.060627  0.053864  0.033361  0.049359 -0.024353  0.020693   \n",
       "88 -0.025444  0.060627  0.053864  0.033361  0.049359 -0.024353  0.020693   \n",
       "89 -0.025444  0.060627  0.053864  0.033361  0.049359 -0.024353  0.020693   \n",
       "90 -0.025444  0.060627  0.053864  0.033361  0.049359 -0.024353  0.020693   \n",
       "\n",
       "        7         8         9     ...  2689  2690  2691  2692      2693  2694  \\\n",
       "1  -0.014916  0.017328 -0.032432  ...   0.0   0.0   0.0   0.0  0.076302   0.0   \n",
       "2  -0.014916  0.017328 -0.032432  ...   0.0   0.0   0.0   0.0  0.076302   0.0   \n",
       "3  -0.014916  0.017328 -0.032432  ...   0.0   0.0   0.0   0.0  0.076302   0.0   \n",
       "4  -0.014916  0.017328 -0.032432  ...   0.0   0.0   0.0   0.0  0.076302   0.0   \n",
       "5  -0.014916  0.017328 -0.032432  ...   0.0   0.0   0.0   0.0  0.076302   0.0   \n",
       "..       ...       ...       ...  ...   ...   ...   ...   ...       ...   ...   \n",
       "86 -0.014916  0.017328 -0.032432  ...   0.0   0.0   0.0   0.0  0.076302   0.0   \n",
       "87 -0.014916  0.017328 -0.032432  ...   0.0   0.0   0.0   0.0  0.076302   0.0   \n",
       "88 -0.014916  0.017328 -0.032432  ...   0.0   0.0   0.0   0.0  0.076302   0.0   \n",
       "89 -0.014916  0.017328 -0.032432  ...   0.0   0.0   0.0   0.0  0.076302   0.0   \n",
       "90 -0.014916  0.017328 -0.032432  ...   0.0   0.0   0.0   0.0  0.076302   0.0   \n",
       "\n",
       "        2695  2696  2697  2698  \n",
       "1   0.107031   0.0   0.0   0.0  \n",
       "2   0.107031   0.0   0.0   0.0  \n",
       "3   0.107031   0.0   0.0   0.0  \n",
       "4   0.107031   0.0   0.0   0.0  \n",
       "5   0.107031   0.0   0.0   0.0  \n",
       "..       ...   ...   ...   ...  \n",
       "86  0.107031   0.0   0.0   0.0  \n",
       "87  0.107031   0.0   0.0   0.0  \n",
       "88  0.107031   0.0   0.0   0.0  \n",
       "89  0.107031   0.0   0.0   0.0  \n",
       "90  0.107031   0.0   0.0   0.0  \n",
       "\n",
       "[90 rows x 2699 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ref=df_train_ref.iloc[1:,:]\n",
    "df_train_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "25377776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "17ab9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = tf.keras.layers.Input(shape=(train_df[0].shape[0],))\n",
    "input_2 = tf.keras.layers.Input(shape=(train_df_ref.shape[1],))\n",
    "\n",
    "common_dense_1 = tf.keras.layers.Dense(128, activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l1(0.1))\n",
    "common_dense_2 = tf.keras.layers.Dense(128, activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "common_dense_3 = tf.keras.layers.Dense(64, activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l1(0.001))\n",
    "common_dense_4 = tf.keras.layers.Dense(64, activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l1(0.001))\n",
    "common_dense_5 = tf.keras.layers.Dense(64, activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l1(0.001))\n",
    "common_dense_6 = tf.keras.layers.Dense(32, activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l1(0.001))\n",
    "\n",
    "vector_1 = common_dense_1(input_1)\n",
    "vector_1 = common_dense_2(vector_1)\n",
    "vector_1 = common_dense_3(vector_1)\n",
    "vector_1 = common_dense_4(vector_1)\n",
    "vector_1 = common_dense_5(vector_1)\n",
    "vector_1 = common_dense_6(vector_1)\n",
    "vector_1 = tf.keras.layers.Flatten()(vector_1)\n",
    "\n",
    "vector_2 = common_dense_1(input_2)\n",
    "vector_2 = common_dense_2(vector_2)\n",
    "vector_2 = common_dense_3(vector_2)\n",
    "vector_2 = common_dense_4(vector_2)\n",
    "vector_2 = common_dense_5(vector_2)\n",
    "vector_2 = common_dense_6(vector_2)\n",
    "vector_2 = tf.keras.layers.Flatten()(vector_2)\n",
    "\n",
    "x3 = tf.keras.layers.Subtract()([vector_1, vector_2])\n",
    "x3 = tf.keras.layers.Multiply()([x3, x3])\n",
    "\n",
    "x1_ = tf.keras.layers.Multiply()([vector_1, vector_1])\n",
    "x2_ = tf.keras.layers.Multiply()([vector_2, vector_2])\n",
    "x4 = tf.keras.layers.Subtract()([x1_, x2_])\n",
    "\n",
    "x5 = tf.keras.layers.Lambda(cosine_distance, output_shape=cos_dist_output_shape)([vector_1, vector_2])\n",
    "    \n",
    "conc = tf.keras.layers.Concatenate(axis=-1)([x5,x4, x3])\n",
    "\n",
    "x = tf.keras.layers.Dense(100, activation=\"relu\", name='conc_layer')(conc)\n",
    "x = tf.keras.layers.Dropout(0.01)(x)\n",
    "out = tf.keras.layers.Dense(1, activation=\"linear\", name ='out')(x)\n",
    "\n",
    "model = tf.keras.models.Model([input_1, input_2], out)\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", metrics=['mse'], optimizer=tf.keras.optimizers.RMSprop(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "051fa351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 2699)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 2699)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 128)          345600      input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 128)          16512       dense_33[0][0]                   \n",
      "                                                                 dense_33[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 64)           8256        dense_34[0][0]                   \n",
      "                                                                 dense_34[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 64)           4160        dense_35[0][0]                   \n",
      "                                                                 dense_35[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 64)           4160        dense_36[0][0]                   \n",
      "                                                                 dense_36[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 32)           2080        dense_37[0][0]                   \n",
      "                                                                 dense_37[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 32)           0           dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 32)           0           dense_38[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 32)           0           flatten_18[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 32)           0           flatten_19[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_15 (Subtract)          (None, 32)           0           flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1)            0           flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_16 (Subtract)          (None, 32)           0           multiply_19[0][0]                \n",
      "                                                                 multiply_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 32)           0           subtract_15[0][0]                \n",
      "                                                                 subtract_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 65)           0           lambda_6[0][0]                   \n",
      "                                                                 subtract_16[0][0]                \n",
      "                                                                 multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conc_layer (Dense)              (None, 100)          6600        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 100)          0           conc_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 1)            101         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 387,469\n",
      "Trainable params: 387,469\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "760b60b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(train_out)), print(type(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ac555566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_df_ref.tolist()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9ad6beb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_df).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5ea34127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "7/7 [==============================] - 3s 104ms/step - loss: 2060.8892 - mse: 1664.2601 - val_loss: 2213.4802 - val_mse: 1998.9154\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 4324.1235 - mse: 4054.4233 - val_loss: 2278.5933 - val_mse: 1943.3184\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 16594.4824 - mse: 16270.7715 - val_loss: 2238.5269 - val_mse: 1929.2438\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 4605.4116 - mse: 4289.9087 - val_loss: 2192.5657 - val_mse: 1865.5123\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1580.6106 - mse: 1266.3501 - val_loss: 577.2558 - val_mse: 268.1102\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 776.6806 - mse: 457.4899 - val_loss: 1573.7498 - val_mse: 1235.2450\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 731.4734 - mse: 405.0965 - val_loss: 547.2683 - val_mse: 236.9630\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 544.4838 - mse: 228.5838 - val_loss: 534.6105 - val_mse: 206.2820\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 814.7088 - mse: 495.4138 - val_loss: 1195.6941 - val_mse: 893.1014\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 605.9831 - mse: 295.8489 - val_loss: 673.4155 - val_mse: 352.8865\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1356.8250 - mse: 1054.1566 - val_loss: 1556.5973 - val_mse: 1269.9863\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1846.8708 - mse: 1558.8779 - val_loss: 1840.0195 - val_mse: 1547.5413\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1166.8429 - mse: 886.9425 - val_loss: 1118.4335 - val_mse: 852.1929\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1589.8075 - mse: 1319.1071 - val_loss: 2611.2556 - val_mse: 2340.0190\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1809.6542 - mse: 1558.9678 - val_loss: 1896.1770 - val_mse: 1675.9623\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1336.5790 - mse: 1116.4481 - val_loss: 1773.7206 - val_mse: 1569.9237\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1215.7838 - mse: 1017.3314 - val_loss: 577.1426 - val_mse: 390.4128\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 996.1530 - mse: 801.4991 - val_loss: 1541.4225 - val_mse: 1346.3884\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1250.9446 - mse: 1055.9818 - val_loss: 1664.0129 - val_mse: 1470.2687\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2066.1201 - mse: 1867.7192 - val_loss: 1698.8474 - val_mse: 1479.0156\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1331.0978 - mse: 1121.3485 - val_loss: 1542.0756 - val_mse: 1343.1565\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1321.1245 - mse: 1124.5874 - val_loss: 1575.2235 - val_mse: 1377.9098\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1186.3239 - mse: 994.1064 - val_loss: 1160.5032 - val_mse: 969.7980\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 636.5004 - mse: 438.8212 - val_loss: 770.7808 - val_mse: 570.9418\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 490.1942 - mse: 291.9244 - val_loss: 352.9833 - val_mse: 156.4086\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 477.1575 - mse: 283.7233 - val_loss: 753.8524 - val_mse: 567.2707\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 422.1879 - mse: 237.0670 - val_loss: 434.9178 - val_mse: 254.1301\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 629.2798 - mse: 445.9792 - val_loss: 1124.1981 - val_mse: 938.4289\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 643.2530 - mse: 448.7706 - val_loss: 587.0817 - val_mse: 391.4154\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 521.2180 - mse: 333.6027 - val_loss: 1241.0341 - val_mse: 1054.3240\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 675.9699 - mse: 486.2115 - val_loss: 342.3158 - val_mse: 158.5607\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 347.8283 - mse: 164.9727 - val_loss: 290.0434 - val_mse: 114.5058\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 230.5145 - mse: 59.7323 - val_loss: 258.8181 - val_mse: 94.0654\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 438.3909 - mse: 269.6664 - val_loss: 968.0274 - val_mse: 791.1481\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 284.6896 - mse: 116.0241 - val_loss: 293.4800 - val_mse: 127.8898\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 347.4091 - mse: 181.0784 - val_loss: 265.3719 - val_mse: 102.1516\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 232.0328 - mse: 71.0525 - val_loss: 330.8926 - val_mse: 174.9051\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 186.9777 - mse: 33.4827 - val_loss: 281.0909 - val_mse: 128.2303\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 389.6642 - mse: 230.5086 - val_loss: 518.4959 - val_mse: 362.8605\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 320.9391 - mse: 162.7700 - val_loss: 234.7494 - val_mse: 78.9337\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 216.3149 - mse: 62.5773 - val_loss: 238.3595 - val_mse: 87.4214\n",
      "Epoch 42/1000\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 227.2541 - mse: 76.7730 - val_loss: 250.9413 - val_mse: 100.5584\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - ETA: 0s - loss: 205.6047 - mse: 57.09 - 0s 30ms/step - loss: 221.7729 - mse: 72.5379 - val_loss: 9992.8389 - val_mse: 9838.4062\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 3128.3772 - mse: 2973.5112 - val_loss: 758.7178 - val_mse: 598.8766\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - ETA: 0s - loss: 258.5521 - mse: 97.993 - 0s 27ms/step - loss: 258.5521 - mse: 97.9930 - val_loss: 261.1848 - val_mse: 100.8177\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 211.5731 - mse: 52.6275 - val_loss: 236.6144 - val_mse: 79.4979\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 177.8866 - mse: 23.2775 - val_loss: 250.6714 - val_mse: 98.2780\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 175.6622 - mse: 24.8735 - val_loss: 226.9857 - val_mse: 78.2422\n",
      "Epoch 49/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 188.6818 - mse: 41.2737 - val_loss: 646.6414 - val_mse: 496.1908\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 237.1994 - mse: 87.3024 - val_loss: 247.0655 - val_mse: 99.1780\n",
      "Epoch 51/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 168.7163 - mse: 22.6779 - val_loss: 208.5365 - val_mse: 64.1967\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 283.6690 - mse: 138.6188 - val_loss: 689.4399 - val_mse: 540.7756\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 195.8400 - mse: 48.8958 - val_loss: 309.1013 - val_mse: 163.7384\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 266.9533 - mse: 120.5509 - val_loss: 221.4103 - val_mse: 73.9610\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 168.7802 - mse: 23.5146 - val_loss: 218.9227 - val_mse: 76.2362\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 146.9710 - mse: 5.9400 - val_loss: 231.4476 - val_mse: 91.9346\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 621.5451 - mse: 477.8617 - val_loss: 1003.9094 - val_mse: 855.9967\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 29ms/step - loss: 596.3452 - mse: 447.9760 - val_loss: 303.4159 - val_mse: 152.0785\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 491.2501 - mse: 340.6851 - val_loss: 228.0526 - val_mse: 78.2294\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 275.7934 - mse: 127.2958 - val_loss: 500.6856 - val_mse: 352.6420\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 236.5732 - mse: 89.5349 - val_loss: 217.7855 - val_mse: 72.3060\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 198.6469 - mse: 53.6054 - val_loss: 225.0077 - val_mse: 79.9439\n",
      "Epoch 63/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 183.0598 - mse: 39.1343 - val_loss: 283.1419 - val_mse: 141.5749\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 173.6821 - mse: 32.7251 - val_loss: 442.2179 - val_mse: 298.7492\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 204.8502 - mse: 62.2630 - val_loss: 310.7967 - val_mse: 166.6136\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 292.1795 - mse: 144.8614 - val_loss: 273.0977 - val_mse: 124.9065\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 158.9077 - mse: 13.7132 - val_loss: 196.9239 - val_mse: 55.6398\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 226.5359 - mse: 85.2598 - val_loss: 597.3478 - val_mse: 454.2083\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 223.4408 - mse: 82.2059 - val_loss: 231.0192 - val_mse: 91.7907\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 174.4565 - mse: 34.7616 - val_loss: 200.9756 - val_mse: 60.8344\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 204.5902 - mse: 64.0694 - val_loss: 214.3109 - val_mse: 74.0272\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 160.0639 - mse: 20.8560 - val_loss: 206.7725 - val_mse: 68.8250\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 199.4364 - mse: 59.0037 - val_loss: 202.9158 - val_mse: 62.6572\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 175.5340 - mse: 35.8220 - val_loss: 234.2007 - val_mse: 94.1790\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 167.9072 - mse: 29.6177 - val_loss: 212.7537 - val_mse: 77.1312\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 148.0616 - mse: 13.2823 - val_loss: 200.2575 - val_mse: 64.8880\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 184.0377 - mse: 47.4699 - val_loss: 238.1289 - val_mse: 103.2114\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 143.3986 - mse: 9.6803 - val_loss: 216.8529 - val_mse: 83.7700\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 241.4693 - mse: 106.2770 - val_loss: 232.0918 - val_mse: 93.5051\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 149.1135 - mse: 12.1521 - val_loss: 285.5666 - val_mse: 150.3583\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 163.5024 - mse: 28.2749 - val_loss: 242.0862 - val_mse: 106.6896\n",
      "Epoch 82/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 149.3431 - mse: 15.3632 - val_loss: 198.3417 - val_mse: 63.6392\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 164.8334 - mse: 29.7070 - val_loss: 199.0247 - val_mse: 64.9392\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 177.6223 - mse: 43.0100 - val_loss: 211.1286 - val_mse: 77.7761\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 181.6901 - mse: 47.5588 - val_loss: 249.3139 - val_mse: 114.6650\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 142.3483 - mse: 9.4884 - val_loss: 294.4758 - val_mse: 162.2207\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 162.8116 - mse: 29.4161 - val_loss: 196.7098 - val_mse: 64.3733\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 159.0955 - mse: 26.6245 - val_loss: 323.7089 - val_mse: 189.3666\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 151.8070 - mse: 19.8554 - val_loss: 205.2246 - val_mse: 74.6639\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 186.3728 - mse: 53.0976 - val_loss: 226.6157 - val_mse: 92.7541\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 147.0801 - mse: 15.0412 - val_loss: 211.2200 - val_mse: 81.7032\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 141.2838 - mse: 12.0181 - val_loss: 240.0764 - val_mse: 110.2334\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 141.8371 - mse: 12.9916 - val_loss: 187.8726 - val_mse: 59.1545\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 177.6407 - mse: 46.6024 - val_loss: 238.0798 - val_mse: 106.4463\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 157.1641 - mse: 27.1532 - val_loss: 225.0607 - val_mse: 96.9667\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 146.7267 - mse: 18.5961 - val_loss: 281.0330 - val_mse: 151.7106\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 151.2491 - mse: 23.2235 - val_loss: 215.3846 - val_mse: 88.0619\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 139.6316 - mse: 12.1155 - val_loss: 220.0766 - val_mse: 92.6594\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 143.9220 - mse: 16.4877 - val_loss: 318.9553 - val_mse: 191.7326\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 140.1199 - mse: 12.9312 - val_loss: 201.1592 - val_mse: 75.1830\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 163.1469 - mse: 35.9622 - val_loss: 271.9193 - val_mse: 142.8627\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 154.1060 - mse: 26.8535 - val_loss: 253.7804 - val_mse: 127.6126\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 135.8750 - mse: 10.6461 - val_loss: 178.4638 - val_mse: 53.3759\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 138.6036 - mse: 12.9149 - val_loss: 225.1737 - val_mse: 99.9474\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 150.2420 - mse: 24.8407 - val_loss: 234.5090 - val_mse: 109.9636\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 140.1157 - mse: 15.2991 - val_loss: 254.3808 - val_mse: 127.6478\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 149.7020 - mse: 23.7207 - val_loss: 181.9157 - val_mse: 57.0715\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 138.1179 - mse: 13.7165 - val_loss: 239.7097 - val_mse: 114.7444\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 148.0147 - mse: 23.3495 - val_loss: 209.2261 - val_mse: 84.3185\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 135.9904 - mse: 11.4907 - val_loss: 223.5646 - val_mse: 99.4414\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 140.2753 - mse: 16.0714 - val_loss: 204.6883 - val_mse: 80.9601\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 136.1075 - mse: 12.0580 - val_loss: 196.9329 - val_mse: 72.8775\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 140.8769 - mse: 16.5935 - val_loss: 219.2367 - val_mse: 95.5394\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 134.6459 - mse: 11.3504 - val_loss: 261.9578 - val_mse: 137.4296\n",
      "Epoch 115/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 157.6420 - mse: 33.9012 - val_loss: 231.9487 - val_mse: 107.0390\n",
      "Epoch 116/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 144.0699 - mse: 19.5968 - val_loss: 191.0631 - val_mse: 66.5810\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 23ms/step - loss: 131.2141 - mse: 7.9863 - val_loss: 213.8176 - val_mse: 91.6732\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 131.4675 - mse: 9.3090 - val_loss: 222.1471 - val_mse: 99.6240\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 141.7890 - mse: 18.8717 - val_loss: 193.8597 - val_mse: 70.9270\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 134.1203 - mse: 11.7279 - val_loss: 268.2077 - val_mse: 144.4055\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 134.7584 - mse: 12.1730 - val_loss: 210.9489 - val_mse: 89.6135\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 133.7035 - mse: 11.9007 - val_loss: 202.3798 - val_mse: 79.8443\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 136.5373 - mse: 14.8060 - val_loss: 179.8715 - val_mse: 58.9263\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 130.3815 - mse: 9.2769 - val_loss: 194.8829 - val_mse: 73.0104\n",
      "Epoch 125/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 138.2912 - mse: 16.3549 - val_loss: 237.3596 - val_mse: 116.2883\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 145.1462 - mse: 23.3311 - val_loss: 185.0183 - val_mse: 62.0000\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 131.8675 - mse: 9.8317 - val_loss: 300.5222 - val_mse: 176.8052\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 140.0099 - mse: 16.9138 - val_loss: 222.8623 - val_mse: 100.1597\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 138.2767 - mse: 16.2073 - val_loss: 193.1577 - val_mse: 71.7819\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 126.5825 - mse: 5.6168 - val_loss: 265.7372 - val_mse: 144.2545\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 138.2665 - mse: 16.9981 - val_loss: 186.3154 - val_mse: 65.1069\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 139.3462 - mse: 17.8545 - val_loss: 206.0663 - val_mse: 83.8163\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 134.8995 - mse: 13.3901 - val_loss: 239.6006 - val_mse: 119.2391\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 127.6884 - mse: 6.8763 - val_loss: 209.2418 - val_mse: 88.1798\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 132.2330 - mse: 11.4385 - val_loss: 266.4555 - val_mse: 145.3428\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 145.5096 - mse: 23.9004 - val_loss: 335.9196 - val_mse: 213.6474\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 139.5162 - mse: 17.3383 - val_loss: 211.6197 - val_mse: 90.9049\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 127.3073 - mse: 6.5587 - val_loss: 203.1653 - val_mse: 82.4520\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 129.2084 - mse: 8.8770 - val_loss: 175.4375 - val_mse: 54.4957\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 133.2715 - mse: 12.2793 - val_loss: 191.6969 - val_mse: 70.7598\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 138.0626 - mse: 17.1367 - val_loss: 179.6828 - val_mse: 58.1617\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 135.1951 - mse: 13.5487 - val_loss: 307.3494 - val_mse: 185.0680\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 152.0980 - mse: 30.1034 - val_loss: 226.0052 - val_mse: 104.2816\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 127.8317 - mse: 6.5567 - val_loss: 202.1008 - val_mse: 81.1849\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 127.3552 - mse: 6.8957 - val_loss: 256.9908 - val_mse: 136.9018\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 135.4469 - mse: 14.6184 - val_loss: 177.7227 - val_mse: 55.7374\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 131.9405 - mse: 10.7215 - val_loss: 202.2313 - val_mse: 82.1644\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 127.1099 - mse: 6.9378 - val_loss: 198.6260 - val_mse: 77.7984\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 136.1883 - mse: 15.3301 - val_loss: 214.2196 - val_mse: 93.4399\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 143.6660 - mse: 22.3107 - val_loss: 226.5020 - val_mse: 104.6872\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 130.5888 - mse: 9.5164 - val_loss: 239.2355 - val_mse: 119.0665\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 129.6519 - mse: 8.9471 - val_loss: 218.1422 - val_mse: 96.8168\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 131.0610 - mse: 10.2948 - val_loss: 198.0462 - val_mse: 76.6743\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 137.7067 - mse: 16.0804 - val_loss: 211.1050 - val_mse: 89.1777\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 131.1038 - mse: 9.9162 - val_loss: 172.4953 - val_mse: 51.7527\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 137.8478 - mse: 16.8287 - val_loss: 204.6553 - val_mse: 83.2402\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 133.0634 - mse: 11.9841 - val_loss: 245.1499 - val_mse: 124.8201\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 144.9303 - mse: 23.9749 - val_loss: 216.4586 - val_mse: 94.5378\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 129.7476 - mse: 8.5634 - val_loss: 196.2956 - val_mse: 76.0163\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 125.0683 - mse: 4.5654 - val_loss: 205.4773 - val_mse: 84.8463\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 135.3270 - mse: 14.3845 - val_loss: 246.9575 - val_mse: 125.9853\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 130.1873 - mse: 9.1999 - val_loss: 242.2823 - val_mse: 120.9950\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 139.5248 - mse: 18.4546 - val_loss: 196.0227 - val_mse: 75.3823\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 125.4737 - mse: 4.9093 - val_loss: 189.5151 - val_mse: 68.9667\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 137.7801 - mse: 17.2888 - val_loss: 228.8596 - val_mse: 108.2583\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 126.2842 - mse: 5.7000 - val_loss: 240.7708 - val_mse: 120.0404\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 139.9964 - mse: 19.1299 - val_loss: 242.1737 - val_mse: 121.1566\n",
      "Epoch 168/1000\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 130.4426 - mse: 9.5659 - val_loss: 166.7102 - val_mse: 45.6222\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 132.7005 - mse: 11.9054 - val_loss: 200.0083 - val_mse: 79.9017\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 127.4204 - mse: 7.3797 - val_loss: 303.0728 - val_mse: 182.2830\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 130.6217 - mse: 10.0128 - val_loss: 183.0820 - val_mse: 62.9070\n",
      "Epoch 172/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 129.0973 - mse: 8.6029 - val_loss: 175.2944 - val_mse: 54.2744\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 163.7810 - mse: 42.3480 - val_loss: 187.1112 - val_mse: 65.5773\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 133.2966 - mse: 11.7467 - val_loss: 208.8620 - val_mse: 87.1453\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 127.8086 - mse: 6.5703 - val_loss: 196.3455 - val_mse: 75.8387\n",
      "Epoch 176/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 21ms/step - loss: 132.0304 - mse: 11.5596 - val_loss: 244.3799 - val_mse: 123.4627\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 131.7467 - mse: 11.1415 - val_loss: 285.8624 - val_mse: 165.2447\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 129.8466 - mse: 9.0018 - val_loss: 202.2527 - val_mse: 81.2068\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 135.1572 - mse: 14.3808 - val_loss: 185.8284 - val_mse: 65.0028\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 127.9790 - mse: 7.2945 - val_loss: 181.8695 - val_mse: 61.3414\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 127.9247 - mse: 7.8249 - val_loss: 206.9484 - val_mse: 86.9023\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 152.0659 - mse: 30.9059 - val_loss: 204.1360 - val_mse: 82.6598\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 125.9541 - mse: 5.2961 - val_loss: 192.2732 - val_mse: 72.3633\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 126.0171 - mse: 5.8008 - val_loss: 181.3886 - val_mse: 60.6650\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 133.1355 - mse: 12.7846 - val_loss: 180.1338 - val_mse: 60.0477\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 134.7372 - mse: 14.1587 - val_loss: 274.9206 - val_mse: 153.2706\n",
      "Epoch 187/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 135.2450 - mse: 14.3147 - val_loss: 252.5411 - val_mse: 132.2519\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 131.6469 - mse: 11.0920 - val_loss: 212.7350 - val_mse: 91.9198\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 123.5709 - mse: 3.6157 - val_loss: 201.8120 - val_mse: 82.6516\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 136.8784 - mse: 16.5703 - val_loss: 179.8646 - val_mse: 58.2579\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 128.2853 - mse: 7.5611 - val_loss: 217.1144 - val_mse: 97.2679\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 126.9130 - mse: 6.9486 - val_loss: 174.2480 - val_mse: 53.5628\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 146.3920 - mse: 25.5485 - val_loss: 190.3271 - val_mse: 69.6534\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 127.6071 - mse: 7.0756 - val_loss: 205.4250 - val_mse: 84.7358\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 123.4556 - mse: 3.5147 - val_loss: 225.1181 - val_mse: 105.9540\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 145.1474 - mse: 24.7182 - val_loss: 183.1321 - val_mse: 61.6998\n",
      "Epoch 197/1000\n",
      "7/7 [==============================] - ETA: 0s - loss: 131.9905 - mse: 11.12 - 0s 29ms/step - loss: 131.9905 - mse: 11.1243 - val_loss: 210.7445 - val_mse: 90.2944\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 124.6454 - mse: 4.3032 - val_loss: 181.3048 - val_mse: 61.0336\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 124.2164 - mse: 4.5615 - val_loss: 265.4590 - val_mse: 145.8083\n",
      "Epoch 200/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 127.6099 - mse: 7.5744 - val_loss: 184.1340 - val_mse: 63.7476\n",
      "Epoch 201/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 139.2909 - mse: 18.5554 - val_loss: 230.4269 - val_mse: 109.7056\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 128.5405 - mse: 7.9615 - val_loss: 242.9580 - val_mse: 121.8696\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 126.9310 - mse: 6.6302 - val_loss: 207.5077 - val_mse: 88.1535\n",
      "Epoch 204/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 124.6701 - mse: 5.0405 - val_loss: 169.2894 - val_mse: 48.7058\n",
      "Epoch 205/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 135.9013 - mse: 15.4577 - val_loss: 180.8520 - val_mse: 61.0218\n",
      "Epoch 206/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 130.3941 - mse: 10.2387 - val_loss: 169.4718 - val_mse: 48.4776\n",
      "Epoch 207/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 133.1691 - mse: 12.5002 - val_loss: 185.4384 - val_mse: 65.2585\n",
      "Epoch 208/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 132.2289 - mse: 12.0599 - val_loss: 219.7613 - val_mse: 99.2826\n",
      "Epoch 209/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 155.3583 - mse: 35.1186 - val_loss: 209.1405 - val_mse: 88.7523\n",
      "Epoch 210/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 125.8233 - mse: 5.5675 - val_loss: 220.0736 - val_mse: 99.7349\n",
      "Epoch 211/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 122.3591 - mse: 2.7313 - val_loss: 181.2877 - val_mse: 62.4338\n",
      "Epoch 212/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 127.8179 - mse: 8.2528 - val_loss: 314.6006 - val_mse: 193.7856\n",
      "Epoch 213/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 129.9749 - mse: 9.5883 - val_loss: 203.9623 - val_mse: 84.2773\n",
      "Epoch 214/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 131.4095 - mse: 11.4871 - val_loss: 192.1229 - val_mse: 71.3881\n",
      "Epoch 215/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 147.9402 - mse: 27.6644 - val_loss: 203.0835 - val_mse: 82.2543\n",
      "Epoch 216/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 131.7363 - mse: 10.9047 - val_loss: 183.0751 - val_mse: 62.3850\n",
      "Epoch 217/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 123.5384 - mse: 3.5081 - val_loss: 174.4462 - val_mse: 55.0132\n",
      "Epoch 218/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 125.7032 - mse: 5.7552 - val_loss: 210.0072 - val_mse: 89.6711\n",
      "Epoch 219/1000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 143.5658 - mse: 23.4737 - val_loss: 210.8205 - val_mse: 89.9009\n",
      "Epoch 220/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 139.6434 - mse: 18.5774 - val_loss: 200.0360 - val_mse: 78.9156\n",
      "Epoch 221/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 125.7282 - mse: 5.3842 - val_loss: 187.9744 - val_mse: 68.5293\n",
      "Epoch 222/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 124.4393 - mse: 4.8473 - val_loss: 189.7642 - val_mse: 69.6051\n",
      "Epoch 223/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 126.5478 - mse: 6.8422 - val_loss: 240.9369 - val_mse: 121.1741\n",
      "Epoch 224/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 130.0851 - mse: 9.7346 - val_loss: 240.0573 - val_mse: 119.3311\n",
      "Epoch 225/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 128.4668 - mse: 8.4926 - val_loss: 233.9994 - val_mse: 114.2218\n",
      "Epoch 226/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 148.0209 - mse: 27.1872 - val_loss: 298.4687 - val_mse: 176.9465\n",
      "Epoch 227/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 135.7645 - mse: 14.3920 - val_loss: 212.1275 - val_mse: 91.5702\n",
      "Epoch 228/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 129.4387 - mse: 8.3984 - val_loss: 299.7930 - val_mse: 178.0184\n",
      "Epoch 229/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 135.6428 - mse: 14.1350 - val_loss: 212.7394 - val_mse: 91.7898\n",
      "Epoch 230/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 131.8924 - mse: 10.8052 - val_loss: 194.3684 - val_mse: 72.7505\n",
      "Epoch 231/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 128.7206 - mse: 7.8883 - val_loss: 196.6641 - val_mse: 76.2446\n",
      "Epoch 232/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 140.3171 - mse: 19.4550 - val_loss: 202.4554 - val_mse: 80.9132\n",
      "Epoch 233/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 124.5926 - mse: 3.9245 - val_loss: 195.9166 - val_mse: 76.2416\n",
      "Epoch 234/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 129.9590 - mse: 9.8267 - val_loss: 214.0450 - val_mse: 93.3967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 131.2358 - mse: 10.7512 - val_loss: 271.8674 - val_mse: 151.2943\n",
      "Epoch 236/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 140.2395 - mse: 19.1767 - val_loss: 185.8062 - val_mse: 64.2442\n",
      "Epoch 237/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 124.8635 - mse: 4.2650 - val_loss: 179.9587 - val_mse: 60.3346\n",
      "Epoch 238/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 140.6432 - mse: 20.2095 - val_loss: 194.8788 - val_mse: 73.5649\n",
      "Epoch 239/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 128.7363 - mse: 8.4221 - val_loss: 176.3336 - val_mse: 56.3078\n",
      "Epoch 240/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 132.0421 - mse: 11.5119 - val_loss: 224.3951 - val_mse: 103.4399\n",
      "Epoch 241/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 127.4149 - mse: 7.2316 - val_loss: 198.0124 - val_mse: 77.9505\n",
      "Epoch 242/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 136.6367 - mse: 15.7076 - val_loss: 233.4443 - val_mse: 111.9236\n",
      "Epoch 243/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 139.4923 - mse: 18.4143 - val_loss: 227.9709 - val_mse: 107.0098\n",
      "Epoch 244/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 129.8045 - mse: 8.9480 - val_loss: 227.4803 - val_mse: 106.5874\n",
      "Epoch 245/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 125.3721 - mse: 5.2551 - val_loss: 254.7355 - val_mse: 135.3100\n",
      "Epoch 246/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 130.7042 - mse: 10.6967 - val_loss: 172.7600 - val_mse: 51.7312\n",
      "Epoch 247/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 144.9032 - mse: 24.2008 - val_loss: 197.4177 - val_mse: 76.5222\n",
      "Epoch 248/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 129.2810 - mse: 8.5498 - val_loss: 189.5078 - val_mse: 68.7176\n",
      "Epoch 249/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 123.4731 - mse: 3.3831 - val_loss: 210.6052 - val_mse: 91.3523\n",
      "Epoch 250/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 124.1995 - mse: 4.7152 - val_loss: 283.4959 - val_mse: 162.5643\n",
      "Epoch 251/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 136.1306 - mse: 15.3019 - val_loss: 189.7369 - val_mse: 69.2672\n",
      "Epoch 252/1000\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 130.1847 - mse: 9.5221 - val_loss: 186.4210 - val_mse: 65.5470\n",
      "Epoch 253/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 136.5789 - mse: 16.0254 - val_loss: 219.1020 - val_mse: 98.7588\n",
      "Epoch 254/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 127.5570 - mse: 7.1841 - val_loss: 176.7051 - val_mse: 55.7054\n",
      "Epoch 255/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 126.4175 - mse: 6.0032 - val_loss: 218.8610 - val_mse: 99.1615\n",
      "Epoch 256/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 128.5174 - mse: 8.8059 - val_loss: 337.1938 - val_mse: 216.3945\n",
      "Epoch 257/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 135.5591 - mse: 14.9203 - val_loss: 219.2356 - val_mse: 99.1341\n",
      "Epoch 258/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 126.2472 - mse: 6.1991 - val_loss: 233.0142 - val_mse: 112.5653\n",
      "Epoch 259/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 135.8940 - mse: 15.7014 - val_loss: 295.4101 - val_mse: 174.8849\n",
      "Epoch 260/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 141.0547 - mse: 20.2252 - val_loss: 191.9114 - val_mse: 71.0141\n",
      "Epoch 261/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 125.1956 - mse: 5.0332 - val_loss: 175.6937 - val_mse: 56.0042\n",
      "Epoch 262/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 134.0986 - mse: 13.9911 - val_loss: 187.2328 - val_mse: 66.6365\n",
      "Epoch 263/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 126.5571 - mse: 6.5126 - val_loss: 187.1793 - val_mse: 67.5157\n",
      "Epoch 264/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 126.2230 - mse: 6.5381 - val_loss: 377.9788 - val_mse: 257.3453\n",
      "Epoch 265/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 141.1561 - mse: 20.4277 - val_loss: 207.5503 - val_mse: 87.2106\n",
      "Epoch 266/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 133.8723 - mse: 13.6000 - val_loss: 214.4771 - val_mse: 94.0331\n",
      "Epoch 267/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 129.6073 - mse: 9.5826 - val_loss: 168.7372 - val_mse: 48.9629\n",
      "Epoch 268/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 126.4627 - mse: 6.4290 - val_loss: 211.3608 - val_mse: 91.2387\n",
      "Epoch 269/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 130.0694 - mse: 10.4060 - val_loss: 175.8781 - val_mse: 55.9043\n",
      "Epoch 270/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 140.7695 - mse: 20.0094 - val_loss: 209.1830 - val_mse: 88.1168\n",
      "Epoch 271/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 125.1167 - mse: 4.8532 - val_loss: 204.1688 - val_mse: 84.8652\n",
      "Epoch 272/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 124.1679 - mse: 4.7677 - val_loss: 168.6689 - val_mse: 48.4148\n",
      "Epoch 273/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 142.3594 - mse: 21.8882 - val_loss: 241.6504 - val_mse: 121.5747\n",
      "Epoch 274/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 131.6889 - mse: 11.1479 - val_loss: 179.8904 - val_mse: 58.6630\n",
      "Epoch 275/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 133.3581 - mse: 13.0663 - val_loss: 203.5515 - val_mse: 83.9195\n",
      "Epoch 276/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 124.1267 - mse: 4.6258 - val_loss: 239.8999 - val_mse: 120.2753\n",
      "Epoch 277/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 127.0422 - mse: 7.5053 - val_loss: 175.2159 - val_mse: 55.4775\n",
      "Epoch 278/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 127.1581 - mse: 7.2801 - val_loss: 220.1814 - val_mse: 99.8224\n",
      "Epoch 279/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 140.2251 - mse: 19.4948 - val_loss: 229.2662 - val_mse: 108.9751\n",
      "Epoch 280/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 128.2551 - mse: 7.6830 - val_loss: 200.2192 - val_mse: 79.6217\n",
      "Epoch 281/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 126.3921 - mse: 6.4553 - val_loss: 211.2273 - val_mse: 91.8530\n",
      "Epoch 282/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 130.1593 - mse: 10.1801 - val_loss: 189.2407 - val_mse: 68.8822\n",
      "Epoch 283/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 133.5587 - mse: 13.1213 - val_loss: 171.5043 - val_mse: 51.0701\n",
      "Epoch 284/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 147.7330 - mse: 26.9625 - val_loss: 218.9310 - val_mse: 97.3538\n",
      "Epoch 285/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 129.1220 - mse: 8.2909 - val_loss: 228.7394 - val_mse: 108.9560\n",
      "Epoch 286/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 130.0507 - mse: 9.7771 - val_loss: 179.5526 - val_mse: 59.1935\n",
      "Epoch 287/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 131.2166 - mse: 11.1565 - val_loss: 171.1985 - val_mse: 51.3809\n",
      "Epoch 288/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 134.7531 - mse: 14.3090 - val_loss: 181.2096 - val_mse: 60.3499\n",
      "Epoch 289/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 135.8008 - mse: 15.4245 - val_loss: 176.0422 - val_mse: 56.0968\n",
      "Epoch 290/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 125.3452 - mse: 5.2627 - val_loss: 190.4613 - val_mse: 70.2005\n",
      "Epoch 291/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 125.5147 - mse: 5.8705 - val_loss: 172.6325 - val_mse: 53.0128\n",
      "Epoch 292/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 147.7681 - mse: 27.0088 - val_loss: 241.8298 - val_mse: 120.4386\n",
      "Epoch 293/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 132.9797 - mse: 12.4120 - val_loss: 179.7702 - val_mse: 60.1117\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 23ms/step - loss: 126.9099 - mse: 7.1145 - val_loss: 194.9270 - val_mse: 74.6028\n",
      "Epoch 295/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 125.5172 - mse: 5.8704 - val_loss: 183.2819 - val_mse: 64.3613\n",
      "Epoch 296/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 131.2434 - mse: 11.8721 - val_loss: 207.9167 - val_mse: 87.2116\n",
      "Epoch 297/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 147.9547 - mse: 27.1762 - val_loss: 220.2463 - val_mse: 100.1802\n",
      "Epoch 298/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 129.7176 - mse: 9.4042 - val_loss: 198.6324 - val_mse: 77.9322\n",
      "Epoch 299/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 125.5523 - mse: 5.6807 - val_loss: 239.7888 - val_mse: 120.3019\n",
      "Epoch 300/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 130.3559 - mse: 10.4716 - val_loss: 173.3573 - val_mse: 53.1846\n",
      "Epoch 301/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 137.0788 - mse: 16.6142 - val_loss: 195.6085 - val_mse: 74.9622\n",
      "Epoch 302/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 125.8752 - mse: 5.6671 - val_loss: 194.6939 - val_mse: 75.0840\n",
      "Epoch 303/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 122.6832 - mse: 3.5829 - val_loss: 269.7768 - val_mse: 150.7267\n",
      "Epoch 304/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 132.2497 - mse: 12.5128 - val_loss: 195.3362 - val_mse: 74.7023\n",
      "Epoch 305/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 135.2703 - mse: 15.1188 - val_loss: 176.4421 - val_mse: 56.2364\n",
      "Epoch 306/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 126.7831 - mse: 6.5526 - val_loss: 230.3563 - val_mse: 109.8339\n",
      "Epoch 307/1000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 130.1821 - mse: 10.1921 - val_loss: 256.5813 - val_mse: 136.4632\n",
      "Epoch 308/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 132.4710 - mse: 12.0779 - val_loss: 176.0491 - val_mse: 55.5818\n",
      "Epoch 309/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 123.0371 - mse: 3.4154 - val_loss: 245.8129 - val_mse: 126.5232\n",
      "Epoch 310/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 154.6105 - mse: 33.9439 - val_loss: 208.0148 - val_mse: 86.2874\n",
      "Epoch 311/1000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 125.1522 - mse: 4.4313 - val_loss: 196.3160 - val_mse: 76.6375\n",
      "Epoch 312/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 121.7652 - mse: 2.1788 - val_loss: 194.6634 - val_mse: 74.9728\n",
      "Epoch 313/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 127.8843 - mse: 8.2028 - val_loss: 257.0895 - val_mse: 136.7032\n",
      "Epoch 314/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 131.4433 - mse: 11.2953 - val_loss: 215.8720 - val_mse: 95.6069\n",
      "Epoch 315/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 124.8563 - mse: 5.3555 - val_loss: 216.8097 - val_mse: 97.7255\n",
      "Epoch 316/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 128.3441 - mse: 8.8451 - val_loss: 203.8601 - val_mse: 83.5473\n",
      "Epoch 317/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 124.1300 - mse: 4.4984 - val_loss: 245.7252 - val_mse: 126.6477\n",
      "Epoch 318/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 135.4498 - mse: 15.4252 - val_loss: 178.3057 - val_mse: 57.1638\n",
      "Epoch 319/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 128.6735 - mse: 8.3260 - val_loss: 217.6142 - val_mse: 98.3147\n",
      "Epoch 320/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 135.0551 - mse: 15.1430 - val_loss: 170.9252 - val_mse: 50.0703\n",
      "Epoch 321/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 126.3773 - mse: 6.1793 - val_loss: 222.4610 - val_mse: 103.4464\n",
      "Epoch 322/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 130.6159 - mse: 10.6520 - val_loss: 194.7942 - val_mse: 74.2448\n",
      "Epoch 323/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 126.1124 - mse: 6.3776 - val_loss: 166.5934 - val_mse: 47.4905\n",
      "Epoch 324/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 134.0272 - mse: 13.6212 - val_loss: 215.0858 - val_mse: 94.0485\n",
      "Epoch 325/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 124.9667 - mse: 4.9071 - val_loss: 242.6763 - val_mse: 123.4456\n",
      "Epoch 326/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 124.6089 - mse: 5.0641 - val_loss: 181.4284 - val_mse: 61.3674\n",
      "Epoch 327/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 126.2662 - mse: 6.6065 - val_loss: 194.1819 - val_mse: 75.0618\n",
      "Epoch 328/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 135.1609 - mse: 15.6438 - val_loss: 180.4038 - val_mse: 59.5006\n",
      "Epoch 329/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 129.2543 - mse: 9.0138 - val_loss: 185.1670 - val_mse: 65.6942\n",
      "Epoch 330/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 124.2171 - mse: 4.8886 - val_loss: 205.3257 - val_mse: 85.4956\n",
      "Epoch 331/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 125.1180 - mse: 5.8013 - val_loss: 172.5416 - val_mse: 53.4375\n",
      "Epoch 332/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 162.2000 - mse: 42.1206 - val_loss: 202.1810 - val_mse: 80.4177\n",
      "Epoch 333/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 127.4364 - mse: 6.5719 - val_loss: 217.8274 - val_mse: 98.1936\n",
      "Epoch 334/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 123.3503 - mse: 3.5670 - val_loss: 195.2097 - val_mse: 75.4943\n",
      "Epoch 335/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 126.0065 - mse: 6.6684 - val_loss: 173.9512 - val_mse: 54.6124\n",
      "Epoch 336/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 125.6578 - mse: 6.3348 - val_loss: 284.3116 - val_mse: 164.4540\n",
      "Epoch 337/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 126.5915 - mse: 7.0276 - val_loss: 241.9648 - val_mse: 122.5628\n",
      "Epoch 338/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 135.0659 - mse: 15.1615 - val_loss: 179.0697 - val_mse: 58.6527\n",
      "Epoch 339/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 143.0820 - mse: 22.7717 - val_loss: 203.7868 - val_mse: 83.8331\n",
      "Epoch 340/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 126.0150 - mse: 6.0750 - val_loss: 200.7349 - val_mse: 80.8170\n",
      "Epoch 341/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 122.2224 - mse: 2.9905 - val_loss: 232.7248 - val_mse: 114.0275\n",
      "Epoch 342/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 125.7939 - mse: 6.7459 - val_loss: 271.9008 - val_mse: 151.9921\n",
      "Epoch 343/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 130.3428 - mse: 10.6251 - val_loss: 232.7783 - val_mse: 113.5385\n",
      "Epoch 344/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 133.2901 - mse: 13.4137 - val_loss: 209.0546 - val_mse: 88.8130\n",
      "Epoch 345/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 132.7874 - mse: 12.9345 - val_loss: 200.7797 - val_mse: 81.6702\n",
      "Epoch 346/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 131.3677 - mse: 11.9510 - val_loss: 178.1315 - val_mse: 57.7165\n",
      "Epoch 347/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 133.2163 - mse: 13.2612 - val_loss: 226.4879 - val_mse: 107.0911\n",
      "Epoch 348/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 123.7862 - mse: 4.4409 - val_loss: 166.6383 - val_mse: 47.0010\n",
      "Epoch 349/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 148.5916 - mse: 28.8076 - val_loss: 232.4137 - val_mse: 111.9802\n",
      "Epoch 350/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 127.7041 - mse: 7.3657 - val_loss: 216.8163 - val_mse: 96.6919\n",
      "Epoch 351/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 124.0976 - mse: 4.4825 - val_loss: 220.1616 - val_mse: 101.2321\n",
      "Epoch 352/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 121.4068 - mse: 2.5482 - val_loss: 188.9703 - val_mse: 69.8722\n",
      "Epoch 353/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 20ms/step - loss: 126.6512 - mse: 7.2944 - val_loss: 188.8976 - val_mse: 69.9051\n",
      "Epoch 354/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 140.1463 - mse: 20.8808 - val_loss: 323.7732 - val_mse: 202.7463\n",
      "Epoch 355/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 127.4316 - mse: 7.0256 - val_loss: 194.1064 - val_mse: 74.6934\n",
      "Epoch 356/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 125.9059 - mse: 6.2509 - val_loss: 235.1410 - val_mse: 114.9700\n",
      "Epoch 357/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 124.9796 - mse: 5.4880 - val_loss: 250.7492 - val_mse: 131.9153\n",
      "Epoch 358/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 133.4724 - mse: 13.5443 - val_loss: 254.5557 - val_mse: 133.9774\n",
      "Epoch 359/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 128.4005 - mse: 8.3715 - val_loss: 191.3257 - val_mse: 72.2928\n",
      "Epoch 360/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 135.6073 - mse: 16.3386 - val_loss: 180.6954 - val_mse: 60.3034\n",
      "Epoch 361/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 126.7723 - mse: 6.9073 - val_loss: 182.3860 - val_mse: 63.4698\n",
      "Epoch 362/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 125.4936 - mse: 6.0992 - val_loss: 184.9030 - val_mse: 65.2125\n",
      "Epoch 363/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 127.0139 - mse: 7.8754 - val_loss: 173.9914 - val_mse: 54.8126\n",
      "Epoch 364/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 140.8420 - mse: 20.9944 - val_loss: 170.2052 - val_mse: 48.8315\n",
      "Epoch 365/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 130.5489 - mse: 10.1608 - val_loss: 240.4639 - val_mse: 121.2381\n",
      "Epoch 366/1000\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 124.9226 - mse: 5.5630 - val_loss: 201.2361 - val_mse: 81.6973\n",
      "Epoch 367/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 125.3006 - mse: 5.9681 - val_loss: 233.1571 - val_mse: 114.3612\n",
      "Epoch 368/1000\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 127.1754 - mse: 7.7053 - val_loss: 184.3417 - val_mse: 64.0345\n",
      "Epoch 369/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 147.2194 - mse: 26.7904 - val_loss: 207.9822 - val_mse: 88.1595\n",
      "Epoch 370/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 128.8076 - mse: 8.9779 - val_loss: 179.7454 - val_mse: 59.4185\n",
      "Epoch 371/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 124.0388 - mse: 4.3453 - val_loss: 217.2742 - val_mse: 98.2697\n",
      "Epoch 372/1000\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 127.6896 - mse: 8.3309 - val_loss: 182.1670 - val_mse: 62.0058\n",
      "Epoch 373/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 128.8085 - mse: 8.9937 - val_loss: 213.5845 - val_mse: 94.3064\n",
      "Epoch 374/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 127.7659 - mse: 8.4866 - val_loss: 210.8036 - val_mse: 91.0592\n",
      "Epoch 375/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 136.1670 - mse: 16.1385 - val_loss: 248.2816 - val_mse: 128.5301\n",
      "Epoch 376/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 123.6595 - mse: 4.1447 - val_loss: 192.5774 - val_mse: 73.2000\n",
      "Epoch 377/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 133.4715 - mse: 13.8095 - val_loss: 243.2638 - val_mse: 123.2819\n",
      "Epoch 378/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 128.7405 - mse: 8.6810 - val_loss: 234.7506 - val_mse: 114.6306\n",
      "Epoch 379/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 125.2708 - mse: 5.7080 - val_loss: 207.2459 - val_mse: 88.5264\n",
      "Epoch 380/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 129.2866 - mse: 10.0401 - val_loss: 293.9300 - val_mse: 173.4164\n",
      "Epoch 381/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 136.3512 - mse: 16.4572 - val_loss: 205.0362 - val_mse: 86.1091\n",
      "Epoch 382/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.0567 - mse: 4.9111 - val_loss: 199.6807 - val_mse: 80.0975\n",
      "Epoch 383/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 134.7709 - mse: 15.6657 - val_loss: 167.5974 - val_mse: 48.0410\n",
      "Epoch 384/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 132.4041 - mse: 12.5038 - val_loss: 203.3058 - val_mse: 83.1756\n",
      "Epoch 385/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 127.8907 - mse: 7.9173 - val_loss: 227.4144 - val_mse: 108.1646\n",
      "Epoch 386/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 124.7182 - mse: 5.3848 - val_loss: 294.8308 - val_mse: 175.1254\n",
      "Epoch 387/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 132.5712 - mse: 12.7373 - val_loss: 200.4076 - val_mse: 81.1850\n",
      "Epoch 388/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 122.5860 - mse: 3.4964 - val_loss: 186.2355 - val_mse: 66.5742\n",
      "Epoch 389/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 137.7510 - mse: 17.7087 - val_loss: 210.4260 - val_mse: 90.6353\n",
      "Epoch 390/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 125.8298 - mse: 6.1507 - val_loss: 193.5765 - val_mse: 73.8419\n",
      "Epoch 391/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.6490 - mse: 5.6371 - val_loss: 173.6138 - val_mse: 54.6512\n",
      "Epoch 392/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 133.7406 - mse: 13.9733 - val_loss: 197.1815 - val_mse: 76.9152\n",
      "Epoch 393/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 125.6290 - mse: 6.0655 - val_loss: 200.3363 - val_mse: 81.2807\n",
      "Epoch 394/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 127.0764 - mse: 7.6844 - val_loss: 206.5004 - val_mse: 86.6051\n",
      "Epoch 395/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 146.1369 - mse: 26.6599 - val_loss: 182.1402 - val_mse: 62.0688\n",
      "Epoch 396/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 126.5395 - mse: 6.3889 - val_loss: 204.3832 - val_mse: 84.3818\n",
      "Epoch 397/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 122.3017 - mse: 2.9509 - val_loss: 251.7563 - val_mse: 132.8868\n",
      "Epoch 398/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 128.3454 - mse: 9.0175 - val_loss: 184.8446 - val_mse: 65.0258\n",
      "Epoch 399/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.5492 - mse: 4.2793 - val_loss: 222.0885 - val_mse: 103.4231\n",
      "Epoch 400/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 142.3992 - mse: 22.7376 - val_loss: 223.9566 - val_mse: 103.6116\n",
      "Epoch 401/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 124.4727 - mse: 5.0429 - val_loss: 176.9742 - val_mse: 58.2296\n",
      "Epoch 402/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.6638 - mse: 3.8423 - val_loss: 186.6656 - val_mse: 67.1798\n",
      "Epoch 403/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 138.7125 - mse: 18.9105 - val_loss: 238.8646 - val_mse: 118.8340\n",
      "Epoch 404/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 127.2533 - mse: 7.5898 - val_loss: 204.4500 - val_mse: 85.1295\n",
      "Epoch 405/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 131.5663 - mse: 12.2715 - val_loss: 202.9169 - val_mse: 83.7673\n",
      "Epoch 406/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 122.2022 - mse: 3.2496 - val_loss: 217.2440 - val_mse: 98.2038\n",
      "Epoch 407/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 134.3618 - mse: 15.1353 - val_loss: 208.8938 - val_mse: 89.3172\n",
      "Epoch 408/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 127.0271 - mse: 7.5497 - val_loss: 228.9112 - val_mse: 109.5587\n",
      "Epoch 409/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 125.1435 - mse: 6.2312 - val_loss: 339.4097 - val_mse: 220.2291\n",
      "Epoch 410/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 134.7574 - mse: 14.8856 - val_loss: 203.4496 - val_mse: 83.3647\n",
      "Epoch 411/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 124.5569 - mse: 5.3531 - val_loss: 275.3400 - val_mse: 156.8144\n",
      "Epoch 412/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 15ms/step - loss: 135.6090 - mse: 15.9834 - val_loss: 218.0939 - val_mse: 97.6667\n",
      "Epoch 413/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 124.9639 - mse: 5.4310 - val_loss: 195.7370 - val_mse: 77.1680\n",
      "Epoch 414/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 124.9534 - mse: 6.1519 - val_loss: 168.2988 - val_mse: 48.3140\n",
      "Epoch 415/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 134.2270 - mse: 14.3735 - val_loss: 267.1100 - val_mse: 147.3877\n",
      "Epoch 416/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 125.4466 - mse: 5.8402 - val_loss: 212.3657 - val_mse: 93.1090\n",
      "Epoch 417/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 130.5433 - mse: 11.1045 - val_loss: 182.3852 - val_mse: 62.8887\n",
      "Epoch 418/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 145.5996 - mse: 25.4762 - val_loss: 203.5721 - val_mse: 82.9886\n",
      "Epoch 419/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 125.3147 - mse: 5.6056 - val_loss: 175.5052 - val_mse: 56.6278\n",
      "Epoch 420/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 123.2082 - mse: 4.3472 - val_loss: 189.2278 - val_mse: 70.2355\n",
      "Epoch 421/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 125.5093 - mse: 6.5675 - val_loss: 209.1020 - val_mse: 90.2338\n",
      "Epoch 422/1000\n",
      "7/7 [==============================] - 291s 48s/step - loss: 122.6098 - mse: 3.8918 - val_loss: 169.7287 - val_mse: 50.1095\n",
      "Epoch 423/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 137.3414 - mse: 17.6450 - val_loss: 194.6582 - val_mse: 74.9305\n",
      "Epoch 424/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 141.0462 - mse: 21.0298 - val_loss: 186.1755 - val_mse: 65.6899\n",
      "Epoch 425/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 123.2067 - mse: 3.6665 - val_loss: 186.7280 - val_mse: 68.3646\n",
      "Epoch 426/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 120.6492 - mse: 2.1818 - val_loss: 186.9560 - val_mse: 68.1771\n",
      "Epoch 427/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 130.9110 - mse: 11.8884 - val_loss: 201.3539 - val_mse: 82.1502\n",
      "Epoch 428/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 125.0075 - mse: 5.9957 - val_loss: 247.4263 - val_mse: 128.1611\n",
      "Epoch 429/1000\n",
      "7/7 [==============================] - 1s 157ms/step - loss: 127.9345 - mse: 9.0272 - val_loss: 332.6590 - val_mse: 213.3989\n",
      "Epoch 430/1000\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 135.0869 - mse: 15.3112 - val_loss: 175.5578 - val_mse: 55.2556\n",
      "Epoch 431/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 131.7926 - mse: 12.1457 - val_loss: 223.6796 - val_mse: 104.5689\n",
      "Epoch 432/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 126.2398 - mse: 7.3545 - val_loss: 178.2101 - val_mse: 58.8317\n",
      "Epoch 433/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 124.3799 - mse: 5.4772 - val_loss: 210.6238 - val_mse: 92.3349\n",
      "Epoch 434/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 144.2736 - mse: 25.4961 - val_loss: 167.0508 - val_mse: 46.3093\n",
      "Epoch 435/1000\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 134.2291 - mse: 13.9670 - val_loss: 204.2364 - val_mse: 84.7790\n",
      "Epoch 436/1000\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 123.9437 - mse: 4.5853 - val_loss: 188.9582 - val_mse: 69.4385\n",
      "Epoch 437/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 122.4738 - mse: 3.4626 - val_loss: 184.4465 - val_mse: 65.8792\n",
      "Epoch 438/1000\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 123.0903 - mse: 4.3919 - val_loss: 260.7315 - val_mse: 141.6024\n",
      "Epoch 439/1000\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 131.0692 - mse: 11.7221 - val_loss: 201.2457 - val_mse: 81.7588\n",
      "Epoch 440/1000\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 128.6366 - mse: 9.3540 - val_loss: 213.7114 - val_mse: 94.2651\n",
      "Epoch 441/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 124.2934 - mse: 5.4279 - val_loss: 240.3289 - val_mse: 121.8608\n",
      "Epoch 442/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 133.6133 - mse: 14.7636 - val_loss: 205.7385 - val_mse: 86.1336\n",
      "Epoch 443/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 122.4790 - mse: 3.5718 - val_loss: 219.9538 - val_mse: 101.8489\n",
      "Epoch 444/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 129.6645 - mse: 10.7904 - val_loss: 179.1254 - val_mse: 58.9273\n",
      "Epoch 445/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 137.8909 - mse: 18.2077 - val_loss: 196.3296 - val_mse: 77.4837\n",
      "Epoch 446/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 125.7145 - mse: 6.5358 - val_loss: 229.8178 - val_mse: 110.2891\n",
      "Epoch 447/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 129.5295 - mse: 10.3390 - val_loss: 210.1209 - val_mse: 90.8954\n",
      "Epoch 448/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 134.0883 - mse: 14.9928 - val_loss: 299.9624 - val_mse: 179.8121\n",
      "Epoch 449/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 127.5898 - mse: 8.0382 - val_loss: 184.3438 - val_mse: 65.0426\n",
      "Epoch 450/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 126.1691 - mse: 6.7807 - val_loss: 203.2417 - val_mse: 83.6176\n",
      "Epoch 451/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 126.3393 - mse: 7.3033 - val_loss: 276.4270 - val_mse: 157.3935\n",
      "Epoch 452/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 130.9727 - mse: 11.6905 - val_loss: 244.3128 - val_mse: 124.4311\n",
      "Epoch 453/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 128.9409 - mse: 9.5101 - val_loss: 259.8198 - val_mse: 140.8805\n",
      "Epoch 454/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 129.6799 - mse: 10.5424 - val_loss: 254.5845 - val_mse: 134.5049\n",
      "Epoch 455/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 134.4282 - mse: 14.5601 - val_loss: 197.2694 - val_mse: 77.9729\n",
      "Epoch 456/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 126.4641 - mse: 7.2053 - val_loss: 213.7010 - val_mse: 94.1087\n",
      "Epoch 457/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 122.7303 - mse: 3.8974 - val_loss: 248.9569 - val_mse: 130.5772\n",
      "Epoch 458/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 125.3311 - mse: 6.6960 - val_loss: 304.1107 - val_mse: 184.4175\n",
      "Epoch 459/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 142.3666 - mse: 22.3768 - val_loss: 215.3539 - val_mse: 95.8368\n",
      "Epoch 460/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 127.2306 - mse: 7.6462 - val_loss: 224.0551 - val_mse: 104.0099\n",
      "Epoch 461/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.6364 - mse: 3.3144 - val_loss: 196.5826 - val_mse: 78.0448\n",
      "Epoch 462/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 132.9082 - mse: 13.3629 - val_loss: 244.6147 - val_mse: 123.7314\n",
      "Epoch 463/1000\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 125.3268 - mse: 5.4707 - val_loss: 183.4621 - val_mse: 64.9015\n",
      "Epoch 464/1000\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 125.3643 - mse: 6.4355 - val_loss: 205.8980 - val_mse: 86.4291\n",
      "Epoch 465/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 131.3848 - mse: 12.1223 - val_loss: 214.8366 - val_mse: 95.5704\n",
      "Epoch 466/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 136.8790 - mse: 17.5482 - val_loss: 239.2934 - val_mse: 119.1335\n",
      "Epoch 467/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 130.2172 - mse: 10.6301 - val_loss: 236.2614 - val_mse: 117.3953\n",
      "Epoch 468/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 122.7286 - mse: 3.8632 - val_loss: 231.5558 - val_mse: 112.4475\n",
      "Epoch 469/1000\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 130.0949 - mse: 11.0813 - val_loss: 221.3156 - val_mse: 102.2824\n",
      "Epoch 470/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 123.6594 - mse: 4.7255 - val_loss: 338.5957 - val_mse: 218.6762\n",
      "Epoch 471/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 18ms/step - loss: 127.8723 - mse: 8.3734 - val_loss: 227.7512 - val_mse: 108.8724\n",
      "Epoch 472/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 145.6551 - mse: 26.0247 - val_loss: 210.7358 - val_mse: 90.8889\n",
      "Epoch 473/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 121.4131 - mse: 2.4957 - val_loss: 214.9399 - val_mse: 96.9138\n",
      "Epoch 474/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 120.1047 - mse: 1.9276 - val_loss: 238.5678 - val_mse: 120.1834\n",
      "Epoch 475/1000\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 129.2205 - mse: 10.3867 - val_loss: 178.3523 - val_mse: 59.2260\n",
      "Epoch 476/1000\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 126.3379 - mse: 7.1086 - val_loss: 203.8881 - val_mse: 83.9425\n",
      "Epoch 477/1000\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 141.2177 - mse: 21.3083 - val_loss: 208.3744 - val_mse: 89.0820\n",
      "Epoch 478/1000\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 121.9443 - mse: 2.8509 - val_loss: 213.0618 - val_mse: 94.1710\n",
      "Epoch 479/1000\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 134.3359 - mse: 15.1983 - val_loss: 222.6565 - val_mse: 103.0031\n",
      "Epoch 480/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 125.4263 - mse: 6.0508 - val_loss: 204.0811 - val_mse: 84.9690\n",
      "Epoch 481/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 123.3036 - mse: 4.6923 - val_loss: 168.3559 - val_mse: 49.2345\n",
      "Epoch 482/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 143.2917 - mse: 23.4914 - val_loss: 217.3776 - val_mse: 97.3203\n",
      "Epoch 483/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.5914 - mse: 4.1972 - val_loss: 187.7279 - val_mse: 69.1129\n",
      "Epoch 484/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 122.5466 - mse: 3.7666 - val_loss: 206.0059 - val_mse: 86.8267\n",
      "Epoch 485/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.9249 - mse: 5.0870 - val_loss: 264.7655 - val_mse: 145.9263\n",
      "Epoch 486/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 130.6857 - mse: 11.2958 - val_loss: 195.0891 - val_mse: 75.5191\n",
      "Epoch 487/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 129.3902 - mse: 10.0694 - val_loss: 187.7858 - val_mse: 68.9162\n",
      "Epoch 488/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 130.8491 - mse: 11.7483 - val_loss: 301.7384 - val_mse: 181.2045\n",
      "Epoch 489/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 139.2064 - mse: 19.2945 - val_loss: 236.4366 - val_mse: 117.7351\n",
      "Epoch 490/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 127.4811 - mse: 8.2519 - val_loss: 216.9025 - val_mse: 97.1684\n",
      "Epoch 491/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.9320 - mse: 7.0544 - val_loss: 173.2587 - val_mse: 54.5404\n",
      "Epoch 492/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 123.2472 - mse: 4.5645 - val_loss: 238.1654 - val_mse: 119.3511\n",
      "Epoch 493/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 129.5891 - mse: 10.4304 - val_loss: 230.6801 - val_mse: 111.3071\n",
      "Epoch 494/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 134.0954 - mse: 14.5296 - val_loss: 176.1202 - val_mse: 55.8276\n",
      "Epoch 495/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 125.8468 - mse: 6.2826 - val_loss: 222.6871 - val_mse: 103.9234\n",
      "Epoch 496/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 126.0543 - mse: 7.0996 - val_loss: 277.6540 - val_mse: 157.9019\n",
      "Epoch 497/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 130.4903 - mse: 10.8653 - val_loss: 177.9782 - val_mse: 58.2685\n",
      "Epoch 498/1000\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 127.9050 - mse: 8.1153 - val_loss: 241.4420 - val_mse: 121.4946\n",
      "Epoch 499/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 125.5315 - mse: 6.1944 - val_loss: 226.3011 - val_mse: 107.7840\n",
      "Epoch 500/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 135.5914 - mse: 16.0484 - val_loss: 208.1151 - val_mse: 87.3325\n",
      "Epoch 501/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 128.4926 - mse: 8.5507 - val_loss: 280.0609 - val_mse: 160.6581\n",
      "Epoch 502/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.5777 - mse: 6.3331 - val_loss: 194.3060 - val_mse: 75.0833\n",
      "Epoch 503/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 128.7383 - mse: 9.5658 - val_loss: 197.8721 - val_mse: 79.0091\n",
      "Epoch 504/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 131.7384 - mse: 12.5892 - val_loss: 237.1492 - val_mse: 117.4048\n",
      "Epoch 505/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 136.7505 - mse: 17.0074 - val_loss: 228.4444 - val_mse: 108.7640\n",
      "Epoch 506/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 127.3316 - mse: 7.7246 - val_loss: 182.8631 - val_mse: 62.8278\n",
      "Epoch 507/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 123.2103 - mse: 4.0418 - val_loss: 243.2542 - val_mse: 124.9943\n",
      "Epoch 508/1000\n",
      "7/7 [==============================] - 0s 49ms/step - loss: 125.7788 - mse: 6.7526 - val_loss: 179.6335 - val_mse: 59.8624\n",
      "Epoch 509/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 129.9053 - mse: 10.4441 - val_loss: 201.3783 - val_mse: 82.6255\n",
      "Epoch 510/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 124.3672 - mse: 5.6472 - val_loss: 255.4802 - val_mse: 136.1596\n",
      "Epoch 511/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 128.9786 - mse: 9.5706 - val_loss: 261.6448 - val_mse: 142.4100\n",
      "Epoch 512/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 139.6031 - mse: 20.0434 - val_loss: 204.1833 - val_mse: 84.2876\n",
      "Epoch 513/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 123.2232 - mse: 4.1624 - val_loss: 176.1738 - val_mse: 57.9218\n",
      "Epoch 514/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.1814 - mse: 6.7445 - val_loss: 186.7536 - val_mse: 67.0684\n",
      "Epoch 515/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 126.4731 - mse: 7.5092 - val_loss: 212.8368 - val_mse: 94.7971\n",
      "Epoch 516/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 128.2112 - mse: 9.5098 - val_loss: 194.5522 - val_mse: 74.5972\n",
      "Epoch 517/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 146.9880 - mse: 27.1102 - val_loss: 213.5023 - val_mse: 93.6220\n",
      "Epoch 518/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 127.6002 - mse: 7.7504 - val_loss: 231.2118 - val_mse: 111.3169\n",
      "Epoch 519/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 121.3430 - mse: 2.1292 - val_loss: 220.1209 - val_mse: 101.9976\n",
      "Epoch 520/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 125.4593 - mse: 6.7594 - val_loss: 265.8924 - val_mse: 145.8491\n",
      "Epoch 521/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 130.5115 - mse: 10.8875 - val_loss: 198.0160 - val_mse: 79.0780\n",
      "Epoch 522/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 121.7736 - mse: 2.9488 - val_loss: 209.8798 - val_mse: 91.1505\n",
      "Epoch 523/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 126.2413 - mse: 7.5338 - val_loss: 287.0258 - val_mse: 167.8937\n",
      "Epoch 524/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 139.1010 - mse: 19.4757 - val_loss: 196.7384 - val_mse: 76.5378\n",
      "Epoch 525/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 122.9435 - mse: 3.5159 - val_loss: 295.6620 - val_mse: 176.9688\n",
      "Epoch 526/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 135.3627 - mse: 15.6891 - val_loss: 211.2419 - val_mse: 91.2594\n",
      "Epoch 527/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.0935 - mse: 3.9106 - val_loss: 201.7881 - val_mse: 83.6211\n",
      "Epoch 528/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 121.7272 - mse: 3.2169 - val_loss: 209.7336 - val_mse: 90.1359\n",
      "Epoch 529/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 139.1202 - mse: 19.3266 - val_loss: 190.7555 - val_mse: 71.2169\n",
      "Epoch 530/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 16ms/step - loss: 129.3212 - mse: 9.8318 - val_loss: 204.3990 - val_mse: 84.4630\n",
      "Epoch 531/1000\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 124.0311 - mse: 4.9168 - val_loss: 231.6828 - val_mse: 113.3119\n",
      "Epoch 532/1000\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 120.5259 - mse: 2.1253 - val_loss: 221.2288 - val_mse: 102.6179\n",
      "Epoch 533/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 139.5656 - mse: 20.9561 - val_loss: 314.2445 - val_mse: 194.7545\n",
      "Epoch 534/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 130.9180 - mse: 11.4215 - val_loss: 200.1688 - val_mse: 80.4878\n",
      "Epoch 535/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 121.3852 - mse: 2.4157 - val_loss: 216.3291 - val_mse: 98.2524\n",
      "Epoch 536/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 125.3436 - mse: 6.8087 - val_loss: 205.8213 - val_mse: 86.4088\n",
      "Epoch 537/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 124.2257 - mse: 5.2741 - val_loss: 333.2656 - val_mse: 214.4440\n",
      "Epoch 538/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 133.0262 - mse: 13.7460 - val_loss: 242.1705 - val_mse: 122.5854\n",
      "Epoch 539/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 124.5939 - mse: 5.5394 - val_loss: 233.8229 - val_mse: 115.3604\n",
      "Epoch 540/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 134.9024 - mse: 15.9045 - val_loss: 190.3988 - val_mse: 69.9809\n",
      "Epoch 541/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 129.4152 - mse: 9.5499 - val_loss: 236.3515 - val_mse: 117.5768\n",
      "Epoch 542/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 124.8175 - mse: 5.8891 - val_loss: 208.6887 - val_mse: 89.2566\n",
      "Epoch 543/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.6241 - mse: 3.8838 - val_loss: 195.0669 - val_mse: 77.0839\n",
      "Epoch 544/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 128.6707 - mse: 10.2212 - val_loss: 246.3733 - val_mse: 126.9940\n",
      "Epoch 545/1000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 159.0427 - mse: 39.2163 - val_loss: 217.9678 - val_mse: 98.2649\n",
      "Epoch 546/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 123.0653 - mse: 3.6221 - val_loss: 218.7085 - val_mse: 99.3972\n",
      "Epoch 547/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 121.3187 - mse: 2.6983 - val_loss: 197.2162 - val_mse: 79.1080\n",
      "Epoch 548/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.2512 - mse: 6.6291 - val_loss: 259.4053 - val_mse: 139.6269\n",
      "Epoch 549/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.3669 - mse: 5.3884 - val_loss: 237.2458 - val_mse: 118.9910\n",
      "Epoch 550/1000\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 126.0078 - mse: 7.0695 - val_loss: 171.5325 - val_mse: 51.3947\n",
      "Epoch 551/1000\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 141.7918 - mse: 21.5107 - val_loss: 221.4797 - val_mse: 101.5484\n",
      "Epoch 552/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.2113 - mse: 4.5888 - val_loss: 266.9987 - val_mse: 147.6303\n",
      "Epoch 553/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 124.9813 - mse: 5.9767 - val_loss: 286.4012 - val_mse: 167.5338\n",
      "Epoch 554/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 128.2763 - mse: 9.0389 - val_loss: 190.6722 - val_mse: 71.0380\n",
      "Epoch 555/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 124.2127 - mse: 5.2859 - val_loss: 220.0762 - val_mse: 101.8214\n",
      "Epoch 556/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 129.7030 - mse: 11.0747 - val_loss: 222.2334 - val_mse: 102.0609\n",
      "Epoch 557/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 127.6996 - mse: 8.0634 - val_loss: 231.2449 - val_mse: 112.1430\n",
      "Epoch 558/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 126.5655 - mse: 7.1806 - val_loss: 207.6676 - val_mse: 88.2776\n",
      "Epoch 559/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 124.4770 - mse: 5.5864 - val_loss: 221.1404 - val_mse: 102.5946\n",
      "Epoch 560/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 135.0861 - mse: 15.8292 - val_loss: 281.9466 - val_mse: 161.2753\n",
      "Epoch 561/1000\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 129.5257 - mse: 9.7209 - val_loss: 218.4580 - val_mse: 99.1949\n",
      "Epoch 562/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 125.1905 - mse: 5.8730 - val_loss: 184.7068 - val_mse: 64.9536\n",
      "Epoch 563/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 125.4007 - mse: 6.1929 - val_loss: 197.2906 - val_mse: 79.0568\n",
      "Epoch 564/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 132.2329 - mse: 13.0982 - val_loss: 192.3116 - val_mse: 71.6868\n",
      "Epoch 565/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 127.6761 - mse: 8.0276 - val_loss: 206.6948 - val_mse: 88.1480\n",
      "Epoch 566/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 121.1480 - mse: 2.6190 - val_loss: 204.6902 - val_mse: 85.6971\n",
      "Epoch 567/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 130.5193 - mse: 11.6829 - val_loss: 216.9061 - val_mse: 97.4575\n",
      "Epoch 568/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 123.8907 - mse: 4.7895 - val_loss: 205.1106 - val_mse: 86.1599\n",
      "Epoch 569/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 156.8646 - mse: 37.9157 - val_loss: 243.9416 - val_mse: 123.9438\n",
      "Epoch 570/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 125.7109 - mse: 5.9348 - val_loss: 227.9707 - val_mse: 108.4003\n",
      "Epoch 571/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 121.4050 - mse: 2.3843 - val_loss: 213.8646 - val_mse: 95.4668\n",
      "Epoch 572/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 124.3528 - mse: 5.4701 - val_loss: 204.1938 - val_mse: 84.6231\n",
      "Epoch 573/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 121.4972 - mse: 2.7745 - val_loss: 197.7013 - val_mse: 79.9961\n",
      "Epoch 574/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 130.3651 - mse: 11.6993 - val_loss: 233.1776 - val_mse: 113.4259\n",
      "Epoch 575/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 125.7436 - mse: 6.8855 - val_loss: 174.6801 - val_mse: 55.7740\n",
      "Epoch 576/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 128.5070 - mse: 9.5613 - val_loss: 180.6798 - val_mse: 60.8356\n",
      "Epoch 577/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 141.7315 - mse: 21.9551 - val_loss: 230.8930 - val_mse: 111.6775\n",
      "Epoch 578/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.1596 - mse: 3.9975 - val_loss: 233.2020 - val_mse: 114.1087\n",
      "Epoch 579/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.6679 - mse: 6.7339 - val_loss: 242.0757 - val_mse: 123.5889\n",
      "Epoch 580/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 123.2132 - mse: 4.4267 - val_loss: 246.0639 - val_mse: 126.9362\n",
      "Epoch 581/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 125.9101 - mse: 7.1340 - val_loss: 185.8560 - val_mse: 67.4237\n",
      "Epoch 582/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 128.0471 - mse: 9.0644 - val_loss: 180.4176 - val_mse: 60.4305\n",
      "Epoch 583/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 130.9406 - mse: 11.0931 - val_loss: 227.9999 - val_mse: 108.8832\n",
      "Epoch 584/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 137.8539 - mse: 18.7108 - val_loss: 240.6897 - val_mse: 120.5772\n",
      "Epoch 585/1000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 125.5769 - mse: 6.0794 - val_loss: 224.1395 - val_mse: 105.5789\n",
      "Epoch 586/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 122.6035 - mse: 3.8673 - val_loss: 228.7574 - val_mse: 109.5480\n",
      "Epoch 587/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 128.7503 - mse: 9.6597 - val_loss: 202.4369 - val_mse: 83.0421\n",
      "Epoch 588/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 162.2410 - mse: 42.5202 - val_loss: 214.5724 - val_mse: 93.9759\n",
      "Epoch 589/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 24ms/step - loss: 125.8098 - mse: 6.0269 - val_loss: 211.7711 - val_mse: 92.8827\n",
      "Epoch 590/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 121.8516 - mse: 2.8247 - val_loss: 223.1000 - val_mse: 103.8743\n",
      "Epoch 591/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 120.3788 - mse: 1.8665 - val_loss: 212.6775 - val_mse: 94.7692\n",
      "Epoch 592/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 120.6256 - mse: 2.3345 - val_loss: 205.9092 - val_mse: 87.0303\n",
      "Epoch 593/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 127.2970 - mse: 8.4230 - val_loss: 201.7638 - val_mse: 82.9975\n",
      "Epoch 594/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 134.0509 - mse: 14.5522 - val_loss: 223.8190 - val_mse: 103.8836\n",
      "Epoch 595/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 127.0039 - mse: 7.7267 - val_loss: 192.1446 - val_mse: 73.2300\n",
      "Epoch 596/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 124.7250 - mse: 5.6930 - val_loss: 218.9138 - val_mse: 99.6571\n",
      "Epoch 597/1000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 130.1451 - mse: 11.1620 - val_loss: 292.7128 - val_mse: 173.2243\n",
      "Epoch 598/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 138.2161 - mse: 18.4079 - val_loss: 231.1512 - val_mse: 111.1662\n",
      "Epoch 599/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 122.5488 - mse: 3.4194 - val_loss: 203.3917 - val_mse: 85.2746\n",
      "Epoch 600/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 121.4373 - mse: 3.1807 - val_loss: 208.8195 - val_mse: 90.0272\n",
      "Epoch 601/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 147.9347 - mse: 29.1599 - val_loss: 217.4593 - val_mse: 97.9879\n",
      "Epoch 602/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 131.4369 - mse: 11.8055 - val_loss: 225.3120 - val_mse: 105.2746\n",
      "Epoch 603/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 123.4542 - mse: 4.4058 - val_loss: 200.2795 - val_mse: 82.0594\n",
      "Epoch 604/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 126.5029 - mse: 7.8641 - val_loss: 195.8916 - val_mse: 76.1765\n",
      "Epoch 605/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 131.4581 - mse: 12.0041 - val_loss: 213.7701 - val_mse: 94.7595\n",
      "Epoch 606/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 123.0066 - mse: 4.1899 - val_loss: 207.0088 - val_mse: 88.2973\n",
      "Epoch 607/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 120.1648 - mse: 2.0283 - val_loss: 177.7310 - val_mse: 59.7261\n",
      "Epoch 608/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 143.6606 - mse: 24.1176 - val_loss: 223.6794 - val_mse: 103.2005\n",
      "Epoch 609/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 122.7888 - mse: 3.3966 - val_loss: 206.9226 - val_mse: 88.6492\n",
      "Epoch 610/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 124.4077 - mse: 5.9735 - val_loss: 175.8429 - val_mse: 56.2975\n",
      "Epoch 611/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 134.2669 - mse: 15.1943 - val_loss: 195.4562 - val_mse: 76.6518\n",
      "Epoch 612/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 123.1851 - mse: 4.3087 - val_loss: 188.5205 - val_mse: 69.4377\n",
      "Epoch 613/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 122.2964 - mse: 3.7746 - val_loss: 218.7737 - val_mse: 100.8141\n",
      "Epoch 614/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 130.4135 - mse: 11.3698 - val_loss: 183.3167 - val_mse: 62.4757\n",
      "Epoch 615/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 130.2693 - mse: 10.3573 - val_loss: 250.2621 - val_mse: 131.3477\n",
      "Epoch 616/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 131.1781 - mse: 11.7986 - val_loss: 211.0250 - val_mse: 91.0809\n",
      "Epoch 617/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.8307 - mse: 6.5371 - val_loss: 234.6482 - val_mse: 115.9646\n",
      "Epoch 618/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 123.1929 - mse: 4.5912 - val_loss: 255.6119 - val_mse: 136.3452\n",
      "Epoch 619/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 125.1910 - mse: 6.5390 - val_loss: 187.3604 - val_mse: 68.8262\n",
      "Epoch 620/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 130.7558 - mse: 11.6913 - val_loss: 210.7064 - val_mse: 90.8655\n",
      "Epoch 621/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 121.7581 - mse: 2.8192 - val_loss: 233.3856 - val_mse: 115.4290\n",
      "Epoch 622/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 134.2560 - mse: 15.0648 - val_loss: 173.0787 - val_mse: 52.7114\n",
      "Epoch 623/1000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 157.4477 - mse: 37.1778 - val_loss: 212.1648 - val_mse: 92.3684\n",
      "Epoch 624/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 123.2905 - mse: 3.7217 - val_loss: 232.5092 - val_mse: 112.9172\n",
      "Epoch 625/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 121.8674 - mse: 2.9052 - val_loss: 204.6342 - val_mse: 86.3977\n",
      "Epoch 626/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 121.8781 - mse: 3.3448 - val_loss: 205.4544 - val_mse: 86.2406\n",
      "Epoch 627/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 131.9771 - mse: 12.8862 - val_loss: 196.0434 - val_mse: 76.8110\n",
      "Epoch 628/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 125.8301 - mse: 6.6146 - val_loss: 227.6793 - val_mse: 108.5474\n",
      "Epoch 629/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 120.0853 - mse: 1.7107 - val_loss: 179.9111 - val_mse: 62.2194\n",
      "Epoch 630/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 129.5714 - mse: 10.5533 - val_loss: 251.3258 - val_mse: 131.2899\n",
      "Epoch 631/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 140.0275 - mse: 20.4229 - val_loss: 224.6353 - val_mse: 105.4257\n",
      "Epoch 632/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.6203 - mse: 4.5567 - val_loss: 214.7216 - val_mse: 95.6760\n",
      "Epoch 633/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 121.7183 - mse: 3.2436 - val_loss: 271.0935 - val_mse: 152.6690\n",
      "Epoch 634/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 125.2739 - mse: 6.3158 - val_loss: 258.6772 - val_mse: 139.0419\n",
      "Epoch 635/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 127.6123 - mse: 8.3638 - val_loss: 221.5711 - val_mse: 103.1412\n",
      "Epoch 636/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 140.9158 - mse: 21.4665 - val_loss: 230.3174 - val_mse: 109.5720\n",
      "Epoch 637/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 125.5597 - mse: 5.7010 - val_loss: 234.4788 - val_mse: 115.5359\n",
      "Epoch 638/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 121.0107 - mse: 2.3193 - val_loss: 203.9312 - val_mse: 85.3169\n",
      "Epoch 639/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 127.7976 - mse: 9.0287 - val_loss: 206.4819 - val_mse: 87.2522\n",
      "Epoch 640/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 130.7704 - mse: 11.1553 - val_loss: 219.7682 - val_mse: 99.8229\n",
      "Epoch 641/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 126.0008 - mse: 6.8344 - val_loss: 227.6974 - val_mse: 109.0171\n",
      "Epoch 642/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 123.0619 - mse: 4.4005 - val_loss: 177.9881 - val_mse: 58.9009\n",
      "Epoch 643/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 132.6951 - mse: 13.2800 - val_loss: 211.2065 - val_mse: 92.2711\n",
      "Epoch 644/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 123.3552 - mse: 4.4013 - val_loss: 223.1024 - val_mse: 104.1539\n",
      "Epoch 645/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 127.9226 - mse: 8.9418 - val_loss: 194.2392 - val_mse: 74.9852\n",
      "Epoch 646/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 138.8900 - mse: 19.5401 - val_loss: 193.7569 - val_mse: 73.4368\n",
      "Epoch 647/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 124.5646 - mse: 5.2038 - val_loss: 221.3750 - val_mse: 102.9555\n",
      "Epoch 648/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 19ms/step - loss: 121.9086 - mse: 3.5696 - val_loss: 237.2213 - val_mse: 118.4784\n",
      "Epoch 649/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 133.4621 - mse: 14.0606 - val_loss: 223.5126 - val_mse: 103.8209\n",
      "Epoch 650/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 128.4214 - mse: 8.8064 - val_loss: 203.9145 - val_mse: 84.4875\n",
      "Epoch 651/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 127.6542 - mse: 8.5499 - val_loss: 256.1118 - val_mse: 137.5823\n",
      "Epoch 652/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 123.5519 - mse: 4.8760 - val_loss: 184.9413 - val_mse: 65.9161\n",
      "Epoch 653/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 130.9209 - mse: 11.6413 - val_loss: 226.8824 - val_mse: 107.8162\n",
      "Epoch 654/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 126.2696 - mse: 7.0174 - val_loss: 221.4946 - val_mse: 102.0204\n",
      "Epoch 655/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 122.6084 - mse: 3.8131 - val_loss: 212.4053 - val_mse: 94.0426\n",
      "Epoch 656/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 128.2211 - mse: 9.4498 - val_loss: 265.9266 - val_mse: 146.0610\n",
      "Epoch 657/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 124.0288 - mse: 5.0247 - val_loss: 187.4170 - val_mse: 68.8488\n",
      "Epoch 658/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 146.7347 - mse: 27.2637 - val_loss: 213.2987 - val_mse: 92.6618\n",
      "Epoch 659/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 122.7815 - mse: 3.1725 - val_loss: 216.5914 - val_mse: 97.9084\n",
      "Epoch 660/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 120.5644 - mse: 1.8496 - val_loss: 224.4270 - val_mse: 105.5229\n",
      "Epoch 661/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.2656 - mse: 3.6499 - val_loss: 215.7040 - val_mse: 97.3884\n",
      "Epoch 662/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 131.5310 - mse: 12.8473 - val_loss: 253.3656 - val_mse: 133.0685\n",
      "Epoch 663/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 156.1133 - mse: 35.6586 - val_loss: 212.9156 - val_mse: 93.1456\n",
      "Epoch 664/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.5822 - mse: 2.9630 - val_loss: 231.2518 - val_mse: 111.6764\n",
      "Epoch 665/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 121.2034 - mse: 2.1952 - val_loss: 205.1880 - val_mse: 86.9549\n",
      "Epoch 666/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 126.1632 - mse: 7.3501 - val_loss: 249.0803 - val_mse: 129.1120\n",
      "Epoch 667/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 124.2050 - mse: 5.1096 - val_loss: 192.4234 - val_mse: 73.8776\n",
      "Epoch 668/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 127.1345 - mse: 8.1698 - val_loss: 200.6446 - val_mse: 80.8245\n",
      "Epoch 669/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 126.4917 - mse: 7.2638 - val_loss: 186.3361 - val_mse: 67.3352\n",
      "Epoch 670/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 130.3262 - mse: 11.0203 - val_loss: 172.0323 - val_mse: 51.3019\n",
      "Epoch 671/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 132.3654 - mse: 12.1476 - val_loss: 212.9449 - val_mse: 93.1338\n",
      "Epoch 672/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 125.9584 - mse: 6.4086 - val_loss: 228.0942 - val_mse: 108.6645\n",
      "Epoch 673/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 123.7609 - mse: 4.9797 - val_loss: 248.1632 - val_mse: 129.7606\n",
      "Epoch 674/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 127.9054 - mse: 8.6497 - val_loss: 230.5583 - val_mse: 110.5485\n",
      "Epoch 675/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 147.6078 - mse: 27.7630 - val_loss: 215.6768 - val_mse: 96.1479\n",
      "Epoch 676/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 124.1142 - mse: 4.6053 - val_loss: 208.0834 - val_mse: 88.4634\n",
      "Epoch 677/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 124.8762 - mse: 5.6832 - val_loss: 201.3491 - val_mse: 82.6296\n",
      "Epoch 678/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 126.9579 - mse: 7.9079 - val_loss: 235.4484 - val_mse: 115.8456\n",
      "Epoch 679/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.2245 - mse: 5.1398 - val_loss: 233.7653 - val_mse: 115.0519\n",
      "Epoch 680/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 123.6559 - mse: 5.1502 - val_loss: 176.7008 - val_mse: 57.0126\n",
      "Epoch 681/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 136.2115 - mse: 16.6921 - val_loss: 215.7334 - val_mse: 96.9009\n",
      "Epoch 682/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 123.9897 - mse: 5.0745 - val_loss: 240.7037 - val_mse: 121.1164\n",
      "Epoch 683/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 129.8820 - mse: 10.4659 - val_loss: 186.7310 - val_mse: 67.2326\n",
      "Epoch 684/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 135.0941 - mse: 15.3276 - val_loss: 213.1645 - val_mse: 92.7012\n",
      "Epoch 685/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.6694 - mse: 4.9595 - val_loss: 225.4727 - val_mse: 106.9915\n",
      "Epoch 686/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 120.7571 - mse: 2.2462 - val_loss: 225.3923 - val_mse: 106.6807\n",
      "Epoch 687/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 135.6170 - mse: 16.3675 - val_loss: 215.5247 - val_mse: 95.9314\n",
      "Epoch 688/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 125.7372 - mse: 6.3583 - val_loss: 217.3330 - val_mse: 97.8173\n",
      "Epoch 689/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 121.3581 - mse: 2.7368 - val_loss: 196.1283 - val_mse: 78.1008\n",
      "Epoch 690/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 122.4788 - mse: 3.9561 - val_loss: 219.4779 - val_mse: 100.1233\n",
      "Epoch 691/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 122.1720 - mse: 3.4394 - val_loss: 191.0704 - val_mse: 72.3417\n",
      "Epoch 692/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 126.8182 - mse: 7.5576 - val_loss: 236.9618 - val_mse: 117.6434\n",
      "Epoch 693/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 152.7024 - mse: 32.8081 - val_loss: 197.6549 - val_mse: 77.4909\n",
      "Epoch 694/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 131.0567 - mse: 10.9390 - val_loss: 191.8320 - val_mse: 71.8519\n",
      "Epoch 695/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 122.6595 - mse: 3.4455 - val_loss: 229.6075 - val_mse: 111.2323\n",
      "Epoch 696/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 120.0637 - mse: 1.6640 - val_loss: 198.3086 - val_mse: 79.5897\n",
      "Epoch 697/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 122.7367 - mse: 4.1869 - val_loss: 234.4449 - val_mse: 116.3981\n",
      "Epoch 698/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 133.3812 - mse: 14.3280 - val_loss: 251.0984 - val_mse: 130.8850\n",
      "Epoch 699/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 131.2328 - mse: 11.5126 - val_loss: 220.0761 - val_mse: 101.1117\n",
      "Epoch 700/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 124.9244 - mse: 6.2317 - val_loss: 177.8784 - val_mse: 58.5565\n",
      "Epoch 701/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 126.1093 - mse: 7.2287 - val_loss: 280.5489 - val_mse: 161.7216\n",
      "Epoch 702/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.0572 - mse: 6.0323 - val_loss: 237.5655 - val_mse: 118.4454\n",
      "Epoch 703/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 130.7167 - mse: 11.3661 - val_loss: 215.0120 - val_mse: 95.8205\n",
      "Epoch 704/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 122.4179 - mse: 3.4849 - val_loss: 229.7168 - val_mse: 110.7559\n",
      "Epoch 705/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 129.4343 - mse: 10.4264 - val_loss: 196.5278 - val_mse: 77.5076\n",
      "Epoch 706/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 133.1437 - mse: 13.6273 - val_loss: 216.5788 - val_mse: 96.4698\n",
      "Epoch 707/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 12ms/step - loss: 123.7576 - mse: 4.5160 - val_loss: 198.0364 - val_mse: 79.4793\n",
      "Epoch 708/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 122.2530 - mse: 3.7205 - val_loss: 230.5166 - val_mse: 111.7010\n",
      "Epoch 709/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 129.2529 - mse: 10.4129 - val_loss: 168.1644 - val_mse: 48.4019\n",
      "Epoch 710/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 133.5497 - mse: 13.6930 - val_loss: 205.3588 - val_mse: 85.6839\n",
      "Epoch 711/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 122.3039 - mse: 3.4992 - val_loss: 208.9169 - val_mse: 91.0408\n",
      "Epoch 712/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 126.3836 - mse: 7.8140 - val_loss: 281.0725 - val_mse: 160.9047\n",
      "Epoch 713/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 125.7662 - mse: 6.3991 - val_loss: 209.7790 - val_mse: 91.5592\n",
      "Epoch 714/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 123.6307 - mse: 5.0923 - val_loss: 267.3990 - val_mse: 148.0673\n",
      "Epoch 715/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 136.0364 - mse: 16.7360 - val_loss: 217.7880 - val_mse: 98.9773\n",
      "Epoch 716/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 122.5046 - mse: 3.9187 - val_loss: 221.6328 - val_mse: 102.6784\n",
      "Epoch 717/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 125.1422 - mse: 6.4081 - val_loss: 183.2802 - val_mse: 64.8607\n",
      "Epoch 718/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 123.4396 - mse: 4.9001 - val_loss: 242.3546 - val_mse: 123.5657\n",
      "Epoch 719/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 143.8006 - mse: 24.0590 - val_loss: 234.1149 - val_mse: 114.5275\n",
      "Epoch 720/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 125.0884 - mse: 5.5861 - val_loss: 212.5531 - val_mse: 93.4925\n",
      "Epoch 721/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.4013 - mse: 4.8100 - val_loss: 203.5607 - val_mse: 85.3740\n",
      "Epoch 722/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 120.7422 - mse: 2.5514 - val_loss: 251.7074 - val_mse: 133.0882\n",
      "Epoch 723/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 131.6955 - mse: 12.5056 - val_loss: 237.9360 - val_mse: 118.3139\n",
      "Epoch 724/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.9342 - mse: 4.5403 - val_loss: 217.4087 - val_mse: 98.2122\n",
      "Epoch 725/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 123.1704 - mse: 4.4334 - val_loss: 175.4629 - val_mse: 56.9045\n",
      "Epoch 726/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 150.8586 - mse: 31.2710 - val_loss: 197.4789 - val_mse: 76.8056\n",
      "Epoch 727/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.0708 - mse: 4.3980 - val_loss: 223.0206 - val_mse: 104.5958\n",
      "Epoch 728/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 122.4979 - mse: 4.0020 - val_loss: 193.7408 - val_mse: 74.6350\n",
      "Epoch 729/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 121.7103 - mse: 3.1627 - val_loss: 208.6365 - val_mse: 90.7576\n",
      "Epoch 730/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 119.3293 - mse: 1.3789 - val_loss: 211.9812 - val_mse: 93.6979\n",
      "Epoch 731/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 130.2993 - mse: 11.7876 - val_loss: 427.2695 - val_mse: 307.6258\n",
      "Epoch 732/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 135.9941 - mse: 15.7555 - val_loss: 211.2620 - val_mse: 90.9410\n",
      "Epoch 733/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.4908 - mse: 5.1235 - val_loss: 239.3853 - val_mse: 121.0309\n",
      "Epoch 734/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.8834 - mse: 7.3889 - val_loss: 187.2287 - val_mse: 67.9512\n",
      "Epoch 735/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.8184 - mse: 5.7672 - val_loss: 240.2162 - val_mse: 121.8754\n",
      "Epoch 736/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 128.1378 - mse: 9.2489 - val_loss: 193.0489 - val_mse: 73.7112\n",
      "Epoch 737/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 123.8557 - mse: 5.1159 - val_loss: 246.2679 - val_mse: 127.7940\n",
      "Epoch 738/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.0696 - mse: 4.4269 - val_loss: 192.2086 - val_mse: 72.9706\n",
      "Epoch 739/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 132.9887 - mse: 14.0098 - val_loss: 569.8481 - val_mse: 449.7868\n",
      "Epoch 740/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 135.6305 - mse: 15.3068 - val_loss: 220.4642 - val_mse: 100.1934\n",
      "Epoch 741/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.2200 - mse: 3.8190 - val_loss: 213.0341 - val_mse: 94.5200\n",
      "Epoch 742/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 122.1289 - mse: 3.5035 - val_loss: 228.1072 - val_mse: 108.9868\n",
      "Epoch 743/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 126.8704 - mse: 8.1389 - val_loss: 191.6680 - val_mse: 72.8730\n",
      "Epoch 744/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.3273 - mse: 5.6143 - val_loss: 185.2098 - val_mse: 66.1708\n",
      "Epoch 745/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 126.9430 - mse: 8.3490 - val_loss: 180.2382 - val_mse: 61.4621\n",
      "Epoch 746/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 135.9603 - mse: 16.5058 - val_loss: 216.6412 - val_mse: 96.4211\n",
      "Epoch 747/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.8946 - mse: 5.6555 - val_loss: 263.7314 - val_mse: 145.2649\n",
      "Epoch 748/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 128.4527 - mse: 9.4231 - val_loss: 213.5918 - val_mse: 94.2739\n",
      "Epoch 749/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.9684 - mse: 7.0564 - val_loss: 206.4283 - val_mse: 87.7895\n",
      "Epoch 750/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 121.6819 - mse: 3.2041 - val_loss: 197.6756 - val_mse: 79.0977\n",
      "Epoch 751/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 133.4884 - mse: 14.4567 - val_loss: 226.3678 - val_mse: 107.0318\n",
      "Epoch 752/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 122.1056 - mse: 3.0132 - val_loss: 208.1350 - val_mse: 89.3589\n",
      "Epoch 753/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 130.8299 - mse: 11.5694 - val_loss: 200.3755 - val_mse: 80.9716\n",
      "Epoch 754/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 122.7963 - mse: 3.8568 - val_loss: 193.0273 - val_mse: 73.9553\n",
      "Epoch 755/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 126.8134 - mse: 7.8774 - val_loss: 217.9317 - val_mse: 99.5738\n",
      "Epoch 756/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 120.8730 - mse: 2.5961 - val_loss: 206.0914 - val_mse: 87.6601\n",
      "Epoch 757/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 124.2934 - mse: 5.9265 - val_loss: 495.7372 - val_mse: 376.5774\n",
      "Epoch 758/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 159.9655 - mse: 40.3252 - val_loss: 224.2912 - val_mse: 104.3532\n",
      "Epoch 759/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 121.9470 - mse: 2.8473 - val_loss: 224.4793 - val_mse: 106.3699\n",
      "Epoch 760/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 120.5449 - mse: 2.3637 - val_loss: 222.2134 - val_mse: 103.7120\n",
      "Epoch 761/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 120.4145 - mse: 2.4120 - val_loss: 192.8735 - val_mse: 75.0553\n",
      "Epoch 762/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.5194 - mse: 5.2219 - val_loss: 202.0992 - val_mse: 83.1716\n",
      "Epoch 763/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 135.1078 - mse: 16.2813 - val_loss: 227.2077 - val_mse: 108.2839\n",
      "Epoch 764/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 126.3069 - mse: 7.1398 - val_loss: 238.4061 - val_mse: 119.2141\n",
      "Epoch 765/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 122.3373 - mse: 3.6872 - val_loss: 248.2928 - val_mse: 130.2270\n",
      "Epoch 766/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 15ms/step - loss: 133.6644 - mse: 14.3937 - val_loss: 201.3186 - val_mse: 81.3493\n",
      "Epoch 767/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 122.6261 - mse: 3.4433 - val_loss: 217.5381 - val_mse: 99.6410\n",
      "Epoch 768/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 165.2194 - mse: 46.3194 - val_loss: 194.0316 - val_mse: 73.4643\n",
      "Epoch 769/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 128.9578 - mse: 9.0116 - val_loss: 225.4976 - val_mse: 106.2124\n",
      "Epoch 770/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 123.9969 - mse: 4.6828 - val_loss: 217.7245 - val_mse: 98.2430\n",
      "Epoch 771/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 121.5941 - mse: 2.7673 - val_loss: 212.8635 - val_mse: 94.8238\n",
      "Epoch 772/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 120.7863 - mse: 2.6294 - val_loss: 211.0515 - val_mse: 92.3300\n",
      "Epoch 773/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 127.2171 - mse: 8.4080 - val_loss: 252.6153 - val_mse: 133.9162\n",
      "Epoch 774/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 145.3866 - mse: 26.3656 - val_loss: 208.8109 - val_mse: 88.7246\n",
      "Epoch 775/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 125.1734 - mse: 5.8400 - val_loss: 228.5500 - val_mse: 110.0980\n",
      "Epoch 776/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 122.6175 - mse: 4.1574 - val_loss: 220.5991 - val_mse: 101.6668\n",
      "Epoch 777/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 122.6542 - mse: 4.2060 - val_loss: 219.6488 - val_mse: 101.9568\n",
      "Epoch 778/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 120.9356 - mse: 3.1437 - val_loss: 283.0707 - val_mse: 164.1366\n",
      "Epoch 779/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 133.2759 - mse: 14.0730 - val_loss: 195.9463 - val_mse: 76.6657\n",
      "Epoch 780/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 124.5684 - mse: 5.4631 - val_loss: 241.5103 - val_mse: 122.8745\n",
      "Epoch 781/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.3940 - mse: 6.5438 - val_loss: 203.2056 - val_mse: 84.3794\n",
      "Epoch 782/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.9485 - mse: 5.9311 - val_loss: 264.9374 - val_mse: 145.4648\n",
      "Epoch 783/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 132.5777 - mse: 13.3716 - val_loss: 178.6858 - val_mse: 58.9666\n",
      "Epoch 784/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 138.1075 - mse: 18.2622 - val_loss: 241.1690 - val_mse: 121.3325\n",
      "Epoch 785/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 122.7732 - mse: 3.5689 - val_loss: 222.0340 - val_mse: 103.6930\n",
      "Epoch 786/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 120.1236 - mse: 1.7831 - val_loss: 199.8541 - val_mse: 81.2020\n",
      "Epoch 787/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 129.8364 - mse: 10.6555 - val_loss: 350.5088 - val_mse: 230.7932\n",
      "Epoch 788/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 143.5070 - mse: 23.9105 - val_loss: 224.7663 - val_mse: 105.5063\n",
      "Epoch 789/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 121.4128 - mse: 2.8786 - val_loss: 214.2699 - val_mse: 96.6159\n",
      "Epoch 790/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.0731 - mse: 3.9313 - val_loss: 245.8556 - val_mse: 126.7568\n",
      "Epoch 791/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 125.5084 - mse: 6.7995 - val_loss: 195.6976 - val_mse: 77.1262\n",
      "Epoch 792/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 126.3457 - mse: 7.3583 - val_loss: 217.0346 - val_mse: 98.1737\n",
      "Epoch 793/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 144.0249 - mse: 25.3778 - val_loss: 174.6687 - val_mse: 54.9034\n",
      "Epoch 794/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 133.6976 - mse: 13.8313 - val_loss: 230.4750 - val_mse: 110.4736\n",
      "Epoch 795/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 123.6576 - mse: 4.3743 - val_loss: 224.6188 - val_mse: 106.2262\n",
      "Epoch 796/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 121.9617 - mse: 3.4527 - val_loss: 221.3230 - val_mse: 102.5636\n",
      "Epoch 797/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.7519 - mse: 4.3192 - val_loss: 232.7187 - val_mse: 114.9314\n",
      "Epoch 798/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 121.0222 - mse: 2.7654 - val_loss: 208.7189 - val_mse: 90.0455\n",
      "Epoch 799/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 143.0895 - mse: 23.6924 - val_loss: 244.9628 - val_mse: 124.8362\n",
      "Epoch 800/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 126.1969 - mse: 6.6270 - val_loss: 265.9002 - val_mse: 146.4974\n",
      "Epoch 801/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 122.5819 - mse: 3.9801 - val_loss: 210.0177 - val_mse: 92.3248\n",
      "Epoch 802/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 121.3240 - mse: 3.0952 - val_loss: 220.1568 - val_mse: 101.3795\n",
      "Epoch 803/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 126.9356 - mse: 8.5102 - val_loss: 180.7479 - val_mse: 62.0387\n",
      "Epoch 804/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 143.6912 - mse: 24.0817 - val_loss: 232.7477 - val_mse: 112.7997\n",
      "Epoch 805/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.3588 - mse: 4.3019 - val_loss: 200.9837 - val_mse: 82.7657\n",
      "Epoch 806/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 124.0351 - mse: 5.4932 - val_loss: 198.9313 - val_mse: 79.5362\n",
      "Epoch 807/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 123.6835 - mse: 4.8190 - val_loss: 193.9647 - val_mse: 75.9905\n",
      "Epoch 808/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 128.8880 - mse: 10.1867 - val_loss: 244.5337 - val_mse: 124.8587\n",
      "Epoch 809/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 123.6864 - mse: 4.8447 - val_loss: 201.7986 - val_mse: 83.8080\n",
      "Epoch 810/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 129.7592 - mse: 11.2007 - val_loss: 291.6826 - val_mse: 171.9259\n",
      "Epoch 811/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 130.3508 - mse: 10.9528 - val_loss: 227.6148 - val_mse: 109.1546\n",
      "Epoch 812/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 122.3754 - mse: 3.9392 - val_loss: 251.2583 - val_mse: 132.5579\n",
      "Epoch 813/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 121.1382 - mse: 2.9826 - val_loss: 189.9430 - val_mse: 72.3105\n",
      "Epoch 814/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 136.8131 - mse: 17.7766 - val_loss: 226.9503 - val_mse: 106.6768\n",
      "Epoch 815/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.2532 - mse: 4.0061 - val_loss: 235.3880 - val_mse: 117.2639\n",
      "Epoch 816/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 127.7623 - mse: 9.2662 - val_loss: 179.0978 - val_mse: 59.3595\n",
      "Epoch 817/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 144.1954 - mse: 24.4330 - val_loss: 230.8792 - val_mse: 111.2955\n",
      "Epoch 818/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.1645 - mse: 3.9488 - val_loss: 214.1440 - val_mse: 95.2770\n",
      "Epoch 819/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 120.6359 - mse: 2.4141 - val_loss: 248.0778 - val_mse: 130.3603\n",
      "Epoch 820/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 133.9680 - mse: 15.3511 - val_loss: 195.4047 - val_mse: 75.0658\n",
      "Epoch 821/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.5288 - mse: 6.2192 - val_loss: 217.3067 - val_mse: 99.1160\n",
      "Epoch 822/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 119.6552 - mse: 1.5928 - val_loss: 220.1339 - val_mse: 101.8624\n",
      "Epoch 823/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 127.0834 - mse: 8.8606 - val_loss: 170.6766 - val_mse: 51.3341\n",
      "Epoch 824/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 131.3208 - mse: 12.0028 - val_loss: 218.7106 - val_mse: 99.4858\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 18ms/step - loss: 143.1073 - mse: 24.3070 - val_loss: 184.5058 - val_mse: 64.9766\n",
      "Epoch 826/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 125.9723 - mse: 6.5814 - val_loss: 225.6131 - val_mse: 106.3552\n",
      "Epoch 827/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 121.1253 - mse: 2.5544 - val_loss: 204.6986 - val_mse: 86.7794\n",
      "Epoch 828/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.2718 - mse: 5.7262 - val_loss: 290.3420 - val_mse: 170.6928\n",
      "Epoch 829/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 124.3642 - mse: 5.5753 - val_loss: 208.5829 - val_mse: 90.9465\n",
      "Epoch 830/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 135.3335 - mse: 16.6314 - val_loss: 313.5555 - val_mse: 193.1920\n",
      "Epoch 831/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 126.2160 - mse: 6.5275 - val_loss: 234.4801 - val_mse: 115.6927\n",
      "Epoch 832/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 122.7369 - mse: 3.8970 - val_loss: 236.8320 - val_mse: 117.7445\n",
      "Epoch 833/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 129.9073 - mse: 11.0481 - val_loss: 185.6175 - val_mse: 66.4507\n",
      "Epoch 834/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 126.8130 - mse: 7.7180 - val_loss: 206.3253 - val_mse: 87.0546\n",
      "Epoch 835/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.0471 - mse: 4.4166 - val_loss: 260.5595 - val_mse: 142.4729\n",
      "Epoch 836/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 127.2157 - mse: 8.3460 - val_loss: 239.8548 - val_mse: 120.2520\n",
      "Epoch 837/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 130.0984 - mse: 10.9041 - val_loss: 218.6057 - val_mse: 100.1855\n",
      "Epoch 838/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 122.2145 - mse: 3.5004 - val_loss: 216.0249 - val_mse: 97.2106\n",
      "Epoch 839/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 123.4837 - mse: 5.1289 - val_loss: 312.4089 - val_mse: 193.7920\n",
      "Epoch 840/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 133.0336 - mse: 13.7118 - val_loss: 232.8017 - val_mse: 113.1450\n",
      "Epoch 841/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 132.1403 - mse: 12.7924 - val_loss: 238.4731 - val_mse: 119.5253\n",
      "Epoch 842/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 127.4574 - mse: 8.4159 - val_loss: 239.6986 - val_mse: 120.2097\n",
      "Epoch 843/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 120.7102 - mse: 2.0448 - val_loss: 207.3993 - val_mse: 89.5085\n",
      "Epoch 844/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 120.0915 - mse: 2.1544 - val_loss: 179.4979 - val_mse: 60.6393\n",
      "Epoch 845/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 148.5261 - mse: 28.7562 - val_loss: 237.3064 - val_mse: 117.6217\n",
      "Epoch 846/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 131.1271 - mse: 11.4688 - val_loss: 206.0948 - val_mse: 86.2280\n",
      "Epoch 847/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 122.0494 - mse: 3.0074 - val_loss: 210.4107 - val_mse: 92.1948\n",
      "Epoch 848/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 120.3264 - mse: 2.1702 - val_loss: 271.9930 - val_mse: 153.2021\n",
      "Epoch 849/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 131.2334 - mse: 11.9014 - val_loss: 215.6714 - val_mse: 96.8814\n",
      "Epoch 850/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 121.2039 - mse: 2.8440 - val_loss: 233.2300 - val_mse: 114.8885\n",
      "Epoch 851/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 124.3843 - mse: 5.7752 - val_loss: 240.6355 - val_mse: 122.1354\n",
      "Epoch 852/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 122.9172 - mse: 4.5604 - val_loss: 259.4420 - val_mse: 140.4819\n",
      "Epoch 853/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 123.9677 - mse: 5.1325 - val_loss: 191.4999 - val_mse: 72.9118\n",
      "Epoch 854/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 146.8012 - mse: 27.4485 - val_loss: 231.5713 - val_mse: 111.4678\n",
      "Epoch 855/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 123.4241 - mse: 4.2310 - val_loss: 212.2215 - val_mse: 93.9928\n",
      "Epoch 856/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 121.3015 - mse: 2.9169 - val_loss: 217.5358 - val_mse: 98.7913\n",
      "Epoch 857/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 135.0336 - mse: 16.1088 - val_loss: 239.0567 - val_mse: 119.8036\n",
      "Epoch 858/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 124.5387 - mse: 5.5145 - val_loss: 229.9763 - val_mse: 110.9750\n",
      "Epoch 859/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 125.3842 - mse: 6.6082 - val_loss: 203.3838 - val_mse: 85.0209\n",
      "Epoch 860/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 124.5335 - mse: 6.0280 - val_loss: 230.9925 - val_mse: 111.9578\n",
      "Epoch 861/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.5499 - mse: 6.7480 - val_loss: 218.9500 - val_mse: 100.6074\n",
      "Epoch 862/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 122.5364 - mse: 4.1716 - val_loss: 195.0814 - val_mse: 76.1039\n",
      "Epoch 863/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 138.7006 - mse: 19.0987 - val_loss: 218.8504 - val_mse: 99.5365\n",
      "Epoch 864/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 123.8820 - mse: 4.8081 - val_loss: 216.7134 - val_mse: 97.9134\n",
      "Epoch 865/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 119.8010 - mse: 1.7414 - val_loss: 232.9196 - val_mse: 115.3059\n",
      "Epoch 866/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 144.3658 - mse: 25.3698 - val_loss: 220.5325 - val_mse: 100.1040\n",
      "Epoch 867/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.9180 - mse: 5.5455 - val_loss: 221.4331 - val_mse: 103.1373\n",
      "Epoch 868/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 130.0994 - mse: 11.7809 - val_loss: 409.3248 - val_mse: 289.5615\n",
      "Epoch 869/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 139.1212 - mse: 19.6065 - val_loss: 217.2725 - val_mse: 98.3141\n",
      "Epoch 870/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 121.1134 - mse: 2.2988 - val_loss: 218.4799 - val_mse: 99.7313\n",
      "Epoch 871/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 122.9461 - mse: 4.4479 - val_loss: 248.4181 - val_mse: 130.0641\n",
      "Epoch 872/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 130.1534 - mse: 11.1056 - val_loss: 220.1169 - val_mse: 100.2802\n",
      "Epoch 873/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 122.3779 - mse: 3.5396 - val_loss: 237.6871 - val_mse: 119.5853\n",
      "Epoch 874/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 120.5979 - mse: 2.5781 - val_loss: 191.3446 - val_mse: 73.0263\n",
      "Epoch 875/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 132.7321 - mse: 14.4983 - val_loss: 185.3225 - val_mse: 66.2952\n",
      "Epoch 876/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 136.0707 - mse: 16.4667 - val_loss: 243.2983 - val_mse: 123.2841\n",
      "Epoch 877/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.1868 - mse: 4.1286 - val_loss: 253.5928 - val_mse: 135.6252\n",
      "Epoch 878/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 120.6637 - mse: 2.4912 - val_loss: 239.1744 - val_mse: 120.5106\n",
      "Epoch 879/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 121.8094 - mse: 3.5367 - val_loss: 257.4779 - val_mse: 139.4552\n",
      "Epoch 880/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 138.2563 - mse: 19.1138 - val_loss: 212.1588 - val_mse: 92.1536\n",
      "Epoch 881/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 126.7168 - mse: 7.5280 - val_loss: 244.2645 - val_mse: 125.9116\n",
      "Epoch 882/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 130.6681 - mse: 11.7535 - val_loss: 208.0343 - val_mse: 88.4355\n",
      "Epoch 883/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 122.2111 - mse: 3.2893 - val_loss: 219.3768 - val_mse: 101.6167\n",
      "Epoch 884/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 15ms/step - loss: 120.9889 - mse: 2.8101 - val_loss: 257.3690 - val_mse: 138.6370\n",
      "Epoch 885/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 125.8552 - mse: 6.9572 - val_loss: 225.5267 - val_mse: 107.0867\n",
      "Epoch 886/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 122.6329 - mse: 4.3619 - val_loss: 248.5271 - val_mse: 129.7589\n",
      "Epoch 887/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 139.3323 - mse: 20.1189 - val_loss: 199.4367 - val_mse: 79.5961\n",
      "Epoch 888/1000\n",
      "7/7 [==============================] - ETA: 0s - loss: 125.5298 - mse: 5.964 - 0s 18ms/step - loss: 125.3497 - mse: 5.9343 - val_loss: 221.2742 - val_mse: 102.4645\n",
      "Epoch 889/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 125.7285 - mse: 7.1331 - val_loss: 224.3788 - val_mse: 105.9918\n",
      "Epoch 890/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 122.5744 - mse: 4.0330 - val_loss: 233.9218 - val_mse: 114.9094\n",
      "Epoch 891/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 121.2315 - mse: 2.9976 - val_loss: 211.2732 - val_mse: 93.6382\n",
      "Epoch 892/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 149.4497 - mse: 30.4723 - val_loss: 240.8866 - val_mse: 120.6550\n",
      "Epoch 893/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 123.6593 - mse: 4.2956 - val_loss: 222.8163 - val_mse: 104.5648\n",
      "Epoch 894/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 120.6116 - mse: 2.2550 - val_loss: 228.6894 - val_mse: 110.1003\n",
      "Epoch 895/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 121.0436 - mse: 2.9519 - val_loss: 262.4318 - val_mse: 144.4258\n",
      "Epoch 896/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 131.5073 - mse: 12.5209 - val_loss: 214.5126 - val_mse: 94.5419\n",
      "Epoch 897/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 129.1749 - mse: 9.8230 - val_loss: 230.5714 - val_mse: 111.8602\n",
      "Epoch 898/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 124.1624 - mse: 5.5480 - val_loss: 215.9727 - val_mse: 97.2924\n",
      "Epoch 899/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 122.1197 - mse: 4.0019 - val_loss: 217.1151 - val_mse: 99.3698\n",
      "Epoch 900/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 130.8661 - mse: 12.2512 - val_loss: 261.7897 - val_mse: 141.9114\n",
      "Epoch 901/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 128.0981 - mse: 8.7459 - val_loss: 212.4004 - val_mse: 93.9030\n",
      "Epoch 902/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.1673 - mse: 4.6084 - val_loss: 270.9488 - val_mse: 151.8244\n",
      "Epoch 903/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 121.4531 - mse: 2.9360 - val_loss: 272.7865 - val_mse: 154.7170\n",
      "Epoch 904/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 140.4556 - mse: 20.8674 - val_loss: 229.2879 - val_mse: 108.5377\n",
      "Epoch 905/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.6115 - mse: 3.9648 - val_loss: 237.7504 - val_mse: 119.4288\n",
      "Epoch 906/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 120.6355 - mse: 2.2595 - val_loss: 248.7971 - val_mse: 130.0702\n",
      "Epoch 907/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.4265 - mse: 6.6985 - val_loss: 211.7246 - val_mse: 93.2736\n",
      "Epoch 908/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 136.4710 - mse: 17.6238 - val_loss: 283.5814 - val_mse: 162.9604\n",
      "Epoch 909/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 125.5819 - mse: 5.8919 - val_loss: 216.3405 - val_mse: 97.8493\n",
      "Epoch 910/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 121.9458 - mse: 3.3583 - val_loss: 222.8079 - val_mse: 104.2115\n",
      "Epoch 911/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 119.8370 - mse: 1.8119 - val_loss: 281.4131 - val_mse: 163.8106\n",
      "Epoch 912/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 142.6151 - mse: 23.5496 - val_loss: 220.7579 - val_mse: 99.9354\n",
      "Epoch 913/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.2389 - mse: 4.5140 - val_loss: 204.2737 - val_mse: 85.8267\n",
      "Epoch 914/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 121.5567 - mse: 3.0417 - val_loss: 233.4918 - val_mse: 114.7444\n",
      "Epoch 915/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 121.4262 - mse: 3.1237 - val_loss: 216.9733 - val_mse: 98.9952\n",
      "Epoch 916/1000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 142.0345 - mse: 22.8143 - val_loss: 258.0699 - val_mse: 137.3313\n",
      "Epoch 917/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 124.3465 - mse: 4.6628 - val_loss: 219.9290 - val_mse: 101.5823\n",
      "Epoch 918/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 121.4691 - mse: 2.9302 - val_loss: 234.7258 - val_mse: 116.0159\n",
      "Epoch 919/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 124.7257 - mse: 6.1296 - val_loss: 223.4749 - val_mse: 105.2091\n",
      "Epoch 920/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 139.4096 - mse: 20.7445 - val_loss: 314.2923 - val_mse: 193.8216\n",
      "Epoch 921/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 134.8371 - mse: 14.7692 - val_loss: 230.0307 - val_mse: 110.7062\n",
      "Epoch 922/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 122.3462 - mse: 3.2681 - val_loss: 228.3640 - val_mse: 109.3001\n",
      "Epoch 923/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 120.1133 - mse: 1.7363 - val_loss: 218.2971 - val_mse: 100.5907\n",
      "Epoch 924/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 120.7967 - mse: 2.9198 - val_loss: 196.3394 - val_mse: 77.3534\n",
      "Epoch 925/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 126.5265 - mse: 7.7432 - val_loss: 202.7572 - val_mse: 84.1908\n",
      "Epoch 926/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 125.0023 - mse: 6.4991 - val_loss: 282.7679 - val_mse: 163.8943\n",
      "Epoch 927/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 141.0369 - mse: 21.9146 - val_loss: 274.5691 - val_mse: 154.7884\n",
      "Epoch 928/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 125.5298 - mse: 5.7903 - val_loss: 246.0645 - val_mse: 126.7398\n",
      "Epoch 929/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.5279 - mse: 3.9323 - val_loss: 205.8378 - val_mse: 87.7746\n",
      "Epoch 930/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 123.0256 - mse: 4.5396 - val_loss: 219.8383 - val_mse: 101.1375\n",
      "Epoch 931/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 119.4730 - mse: 1.5266 - val_loss: 273.0278 - val_mse: 155.4348\n",
      "Epoch 932/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 129.9264 - mse: 11.6890 - val_loss: 174.4731 - val_mse: 54.4357\n",
      "Epoch 933/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 132.7300 - mse: 13.1495 - val_loss: 233.2238 - val_mse: 114.5867\n",
      "Epoch 934/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 123.2791 - mse: 4.6569 - val_loss: 198.1357 - val_mse: 79.1353\n",
      "Epoch 935/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 124.7314 - mse: 6.0790 - val_loss: 252.4134 - val_mse: 134.1324\n",
      "Epoch 936/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 124.1868 - mse: 5.7618 - val_loss: 381.3429 - val_mse: 261.3916\n",
      "Epoch 937/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 141.0656 - mse: 21.2831 - val_loss: 242.9938 - val_mse: 123.9207\n",
      "Epoch 938/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.1808 - mse: 3.3805 - val_loss: 226.1571 - val_mse: 107.1918\n",
      "Epoch 939/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 123.2889 - mse: 4.7241 - val_loss: 258.1757 - val_mse: 139.9574\n",
      "Epoch 940/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 132.6684 - mse: 13.6936 - val_loss: 217.3696 - val_mse: 98.1376\n",
      "Epoch 941/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 120.1196 - mse: 1.7587 - val_loss: 230.3129 - val_mse: 112.7991\n",
      "Epoch 942/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 123.3526 - mse: 5.5717 - val_loss: 205.9859 - val_mse: 86.4860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 943/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 133.6832 - mse: 14.1054 - val_loss: 265.5468 - val_mse: 146.2721\n",
      "Epoch 944/1000\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 123.1302 - mse: 4.0486 - val_loss: 214.4320 - val_mse: 95.8399\n",
      "Epoch 945/1000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 120.1520 - mse: 2.1845 - val_loss: 182.1214 - val_mse: 64.3704\n",
      "Epoch 946/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 133.8449 - mse: 14.9583 - val_loss: 227.1311 - val_mse: 107.6033\n",
      "Epoch 947/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 122.0760 - mse: 3.4499 - val_loss: 235.9640 - val_mse: 118.1345\n",
      "Epoch 948/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.0266 - mse: 3.8642 - val_loss: 185.5580 - val_mse: 66.2933\n",
      "Epoch 949/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 135.5291 - mse: 15.7161 - val_loss: 226.3821 - val_mse: 106.7118\n",
      "Epoch 950/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 125.6084 - mse: 6.4400 - val_loss: 197.4137 - val_mse: 77.9424\n",
      "Epoch 951/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 123.2756 - mse: 4.5576 - val_loss: 219.3135 - val_mse: 101.4825\n",
      "Epoch 952/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 125.0554 - mse: 6.8195 - val_loss: 345.9626 - val_mse: 226.4308\n",
      "Epoch 953/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 140.6911 - mse: 20.8931 - val_loss: 216.3670 - val_mse: 96.7926\n",
      "Epoch 954/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 127.7274 - mse: 8.3204 - val_loss: 213.1311 - val_mse: 93.6058\n",
      "Epoch 955/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 124.0184 - mse: 4.9098 - val_loss: 225.2189 - val_mse: 106.9195\n",
      "Epoch 956/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 123.2530 - mse: 4.7764 - val_loss: 214.5126 - val_mse: 95.6495\n",
      "Epoch 957/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 127.1675 - mse: 8.5815 - val_loss: 236.8684 - val_mse: 118.2802\n",
      "Epoch 958/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 126.0173 - mse: 7.1227 - val_loss: 218.9745 - val_mse: 99.7214\n",
      "Epoch 959/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 130.1767 - mse: 11.2783 - val_loss: 197.0224 - val_mse: 77.7838\n",
      "Epoch 960/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 126.9573 - mse: 7.6744 - val_loss: 267.3257 - val_mse: 147.7503\n",
      "Epoch 961/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 127.4989 - mse: 8.4825 - val_loss: 238.1180 - val_mse: 119.7613\n",
      "Epoch 962/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.3093 - mse: 3.9317 - val_loss: 270.8035 - val_mse: 151.9176\n",
      "Epoch 963/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 128.2531 - mse: 9.3940 - val_loss: 216.6298 - val_mse: 97.9283\n",
      "Epoch 964/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 123.6765 - mse: 5.2194 - val_loss: 270.2176 - val_mse: 151.2354\n",
      "Epoch 965/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 130.1910 - mse: 10.8784 - val_loss: 185.9937 - val_mse: 66.7198\n",
      "Epoch 966/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 122.4220 - mse: 3.5019 - val_loss: 241.8529 - val_mse: 123.0432\n",
      "Epoch 967/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 122.0379 - mse: 3.6643 - val_loss: 242.3289 - val_mse: 124.2813\n",
      "Epoch 968/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 143.5762 - mse: 24.1670 - val_loss: 223.6491 - val_mse: 102.6346\n",
      "Epoch 969/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 127.6579 - mse: 7.7630 - val_loss: 225.5791 - val_mse: 106.6201\n",
      "Epoch 970/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 121.5540 - mse: 2.6916 - val_loss: 243.8101 - val_mse: 124.8154\n",
      "Epoch 971/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 122.0921 - mse: 3.4074 - val_loss: 220.4294 - val_mse: 102.1768\n",
      "Epoch 972/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 119.7289 - mse: 1.7364 - val_loss: 281.5867 - val_mse: 162.8774\n",
      "Epoch 973/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 138.6600 - mse: 19.3084 - val_loss: 235.4957 - val_mse: 115.8542\n",
      "Epoch 974/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 124.2054 - mse: 4.9511 - val_loss: 237.2059 - val_mse: 118.3877\n",
      "Epoch 975/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 122.2297 - mse: 3.9711 - val_loss: 207.9764 - val_mse: 89.9283\n",
      "Epoch 976/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 126.5901 - mse: 8.0915 - val_loss: 377.3573 - val_mse: 257.1350\n",
      "Epoch 977/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 131.3942 - mse: 11.5498 - val_loss: 227.4746 - val_mse: 108.7085\n",
      "Epoch 978/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 123.5564 - mse: 4.8266 - val_loss: 225.8560 - val_mse: 107.1581\n",
      "Epoch 979/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 122.7840 - mse: 4.4539 - val_loss: 208.6729 - val_mse: 90.7828\n",
      "Epoch 980/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 126.2870 - mse: 8.2050 - val_loss: 182.3383 - val_mse: 62.5629\n",
      "Epoch 981/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 131.8158 - mse: 12.3750 - val_loss: 217.7762 - val_mse: 98.9247\n",
      "Epoch 982/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 121.5896 - mse: 3.0544 - val_loss: 201.4633 - val_mse: 82.9274\n",
      "Epoch 983/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 127.1259 - mse: 8.2881 - val_loss: 230.7109 - val_mse: 112.1800\n",
      "Epoch 984/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 127.7821 - mse: 9.0401 - val_loss: 192.1088 - val_mse: 71.9924\n",
      "Epoch 985/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 126.6883 - mse: 7.2866 - val_loss: 233.5587 - val_mse: 115.2389\n",
      "Epoch 986/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 128.3095 - mse: 9.2310 - val_loss: 224.8676 - val_mse: 105.3674\n",
      "Epoch 987/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 120.6990 - mse: 2.1554 - val_loss: 210.4638 - val_mse: 92.9663\n",
      "Epoch 988/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 120.0507 - mse: 2.2657 - val_loss: 188.2225 - val_mse: 69.4988\n",
      "Epoch 989/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 134.0701 - mse: 14.7823 - val_loss: 246.7033 - val_mse: 127.4097\n",
      "Epoch 990/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 126.0174 - mse: 6.9492 - val_loss: 189.7048 - val_mse: 70.5647\n",
      "Epoch 991/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.9461 - mse: 4.3506 - val_loss: 211.8519 - val_mse: 93.8385\n",
      "Epoch 992/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 121.2816 - mse: 3.2459 - val_loss: 325.6195 - val_mse: 206.4234\n",
      "Epoch 993/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 138.5456 - mse: 19.0581 - val_loss: 220.0752 - val_mse: 101.0775\n",
      "Epoch 994/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 122.3708 - mse: 3.5894 - val_loss: 228.7670 - val_mse: 110.1508\n",
      "Epoch 995/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 121.9015 - mse: 3.6964 - val_loss: 261.7095 - val_mse: 143.8363\n",
      "Epoch 996/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 129.8385 - mse: 10.9720 - val_loss: 228.8930 - val_mse: 108.9543\n",
      "Epoch 997/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 122.2832 - mse: 3.3985 - val_loss: 230.9743 - val_mse: 113.0415\n",
      "Epoch 998/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 126.3078 - mse: 7.4299 - val_loss: 214.7513 - val_mse: 95.4211\n",
      "Epoch 999/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 122.6880 - mse: 4.0193 - val_loss: 193.5321 - val_mse: 75.2900\n",
      "Epoch 1000/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 132.9534 - mse: 13.6402 - val_loss: 236.8446 - val_mse: 116.8892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28193512ca0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([df_train,df_train_ref],train_out,epochs = 1000,batch_size=9,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c83d348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fd9e5e04",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'Layer.add_loss.<locals>._tag_callable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-a15f3e3ff01f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'Layer.add_loss.<locals>._tag_callable'"
     ]
    }
   ],
   "source": [
    "pickle.dump(model,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9c0125ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anupa\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "364361f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CandidateID</th>\n",
       "      <th>bert-tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>candidate_014</td>\n",
       "      <td>[-0.019855467602610588, 0.05377298220992088, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>candidate_098</td>\n",
       "      <td>[-0.0040850285440683365, 0.06921227276325226, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate_075</td>\n",
       "      <td>[-0.051488179713487625, 0.04464828595519066, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>candidate_016</td>\n",
       "      <td>[-0.03214683011174202, 0.03543371334671974, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candidate_131</td>\n",
       "      <td>[-0.017553701996803284, 0.05723244696855545, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CandidateID                                         bert-tfidf\n",
       "0  candidate_014  [-0.019855467602610588, 0.05377298220992088, 0...\n",
       "1  candidate_098  [-0.0040850285440683365, 0.06921227276325226, ...\n",
       "2  candidate_075  [-0.051488179713487625, 0.04464828595519066, 0...\n",
       "3  candidate_016  [-0.03214683011174202, 0.03543371334671974, 0....\n",
       "4  candidate_131  [-0.017553701996803284, 0.05723244696855545, 0..."
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "76b217e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "My_data = test['bert-tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bcf4028c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(My_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8bb8b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "My_data = np.array(My_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "397afb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([-0.01985547,  0.05377298,  0.12351051, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.00408503,  0.06921227,  0.10084466, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.05148818,  0.04464829,  0.08095501, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03214683,  0.03543371,  0.09734838, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0175537 ,  0.05723245,  0.10827108, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02833689,  0.04094543,  0.10830949, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03630507,  0.03700452,  0.11058752, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02589451,  0.03874171,  0.09175021, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02577159,  0.02714813,  0.11174339, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04506445,  0.05341544,  0.06083561, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0323845 ,  0.05198789,  0.11239786, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04456305,  0.05243633,  0.05830862, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0148056 ,  0.03960979,  0.10200739, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02751881,  0.03860844,  0.11622132, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03559736,  0.04929333,  0.08089998, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02516822,  0.04645501,  0.08943838, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04329772,  0.0329918 ,  0.1065255 , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02675398,  0.03622442,  0.10272373, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.06203005,  0.04485807,  0.07050712, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.01927307,  0.05032561,  0.10774645, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04614924,  0.04090568,  0.12297043, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.01682703,  0.0550396 ,  0.11168469, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03519886,  0.03380708,  0.09037999, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.01565384,  0.03904695,  0.10448083, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03319838,  0.05371045,  0.06356291, ...,  0.13226959,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03264033,  0.05720138,  0.08107834, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04105581,  0.05735105,  0.08809634, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04595823,  0.03931864,  0.07082984, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.01999543,  0.07452732,  0.0837108 , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.01576315,  0.0589408 ,  0.08054295, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.05179347,  0.04287488,  0.09549261, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02769568,  0.04284542,  0.08659866, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.05235672,  0.03372306,  0.05385536, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03135359,  0.04300379,  0.07773427, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02346189,  0.04329222,  0.12200237, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04464052,  0.03644805,  0.10321224, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02365144,  0.04542981,  0.091509  , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.01151752,  0.05051121,  0.11071604, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02710391,  0.04494127,  0.09396769, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03843168,  0.04032033,  0.11599218, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04008814,  0.05405986,  0.10294451, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02542816,  0.0526766 ,  0.07780536, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02456416,  0.05044578,  0.09563956, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03235262,  0.02923541,  0.0989872 , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03462721,  0.05160401,  0.09782447, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02772518,  0.04356367,  0.07018701, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.01500331,  0.03641393,  0.09991635, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02255115,  0.02407395,  0.14577657, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02261252,  0.05861785,  0.09301226, ...,  0.23133293,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.05544295,  0.04690409,  0.05750429, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0512202 ,  0.03844246,  0.09166708, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.06728598,  0.02149365,  0.08607797, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0434534 ,  0.02800479,  0.09877052, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02745641,  0.06611358,  0.07708345, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.03577078,  0.05647472,  0.06220488, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.02749968,  0.03951648,  0.10080401, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04392732,  0.03139911,  0.10534017, ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04428954,  0.04545346,  0.1055997 , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.04627326,  0.03203341,  0.0743487 , ...,  0.        ,\n",
       "        0.        ,  0.        ]),\n",
       "       array([-0.0434352 ,  0.05773341,  0.06990843, ...,  0.        ,\n",
       "        0.        ,  0.        ])], dtype=object)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "15d25e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df  = pd.DataFrame(np.arange(2699).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b266dd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in My_data.tolist():\n",
    "    test_df = test_df.append(pd.DataFrame(i.reshape(1,-1)),ignore_index=True)\n",
    "My_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b64fd7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 2699)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "136e57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f74c3b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2699)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f4e8fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = model.predict([test_df,df_train_ref.iloc[:60,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "db1287c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5cad2aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Match Percentage'] = test_label\n",
    "test = test.drop('bert-tfidf',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d4325387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CandidateID</th>\n",
       "      <th>Match Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>candidate_014</td>\n",
       "      <td>27.903101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>candidate_098</td>\n",
       "      <td>42.471138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candidate_075</td>\n",
       "      <td>20.565212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>candidate_016</td>\n",
       "      <td>42.676170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>candidate_131</td>\n",
       "      <td>28.673000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CandidateID  Match Percentage\n",
       "0  candidate_014         27.903101\n",
       "1  candidate_098         42.471138\n",
       "2  candidate_075         20.565212\n",
       "3  candidate_016         42.676170\n",
       "4  candidate_131         28.673000"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "95ab39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae49c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
